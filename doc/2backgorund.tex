\chapter{Background}
\label{ch:back}
\section{Context of the project}
\label{sec:back:context}
First, this section will scope the efforts the project. This will be achieved by two analyses. Firstly, the set of target applications will be described in abstract concepts. Secondly, the efforts will be focussed  be defining the stakeholders that are affected be an implementation of the intended monitoring platform

\subsubsection*{Defining the set of applications}
As stated before, the concrete group of target applications for the QoS monitoring platform is WSN and IoT applications. However, the group of applications can be defined more conceptually by specifying and parametrizing the data emitted by them and expected after processing. For the purpose of scoping, an implementation-agnostic view will be taken regarding the intended platform. This brings the focus to intended inputs, expected outputs and their contrasts, without assumptions of the internals of the platform.

Firstly, there is the issue of \emph{individual information capacity}. Individual messages presented to the platform contain very little individual capacity for information. Some information can be extrapolated from it, but only about the device that emitted it and at the exact moment the measurements were taken. Though, for example, detection of failure of a single node is an important task, it has little impact on the application at large if this application concerns thousands of sensors. This immediately identifies a second feature of the emitted data, in that it is extremely multi-source. The data originates from an incredible amount of distributed devices. This entails that, though the measured data points from similar devices describe similar data, the aggregation of data from these sources is not a trivial task \cite{iot_big_data_difficulties}. Not only is a series of data temporally relevant, it is also related across the plain of geographically distributed sensor devices. Finally, the huge amount of devices and the dynamic nature of sensor networks and IoT induces a high variety of scale. Therefore, any back-end application --- main or auxiliary --- should anticipate and provide a sufficient potential for scalability. Conversely, the outcomes of the platform are considered. The platform is expected to output a relatively small amount of high-information actions, alerts and reports. The high-information consequences are contrary to the low-information capacity of individual device messages. Likewise, the moderately small number of output responses/events contradicts the immense influx of data-messages into the platform. This entails that somewhere in the application the data is transformed and condensed.

The transformation from low individual information capacity to high information messages can be achieved through three means. The first is enrichment, which uses outside sources to annotate and amend the data in a device measurement message (e.g. device location data extracted from a server-side database) \cite{data_enrichment}. The second is transformation, which takes raw low-level data points and performs calculations on them to transpose it to higher-level information (e.g. combining location data and time to calculate the speed of an object) \cite{information_transformation}. The third method is data aggregation and reduction. This method joins and merges related data points across several --- and often vast amounts of --- input messages to formulate a single output message containing a few data points, depicting some collective parameters of the domain \cite{information_transformation}. Again, the reach of this domain can be temporally, geographically, etcetera. The first two methods operate on individual data entries emitted by sensors. Hence, they can be easily parallellized and are thus incredibly scalable \cite{data_mining_and_cleaning}. However, the aggregation implies an eventual reduction into a single snapshot on a single machine. This introduces possible single points of failures or congestion, and if adequate precautions are not taken scalability is lost.

To summarize, the input data is characterized by \emph{low individual information value}, \emph{multi-source} and \emph{extremely high volumes}. Conversely, the output is characterized by a \emph{finite} number of \emph{high information value} whose data processing will require \emph{scalable data enrichment and aggregation}. These will be the parameters of the scope of applications observed by the platform and the successive applications the platform will serve.

\subsubsection*{Stakeholder analysis}
Another approach to scope the efforts is by identifying the stakeholders of the platform. This will be performed by analogy of the Onion Stakeholder Model \cite{onion}. This model divides stakeholders in consecutive layers, ordered by the degree of interaction and benefits received from the product. For this stakeholder division both the platform to be developed and potential future implementations of it will be considered as the \textbf{Product}. Intuitively, this project definition would result in a two level product in the model, with the platform as core and the group of all instantiations as the first layer around it. However, since this analysis focusses on human stakeholders, it will be treated as a single instance in the application of the model. A visual representation of the application of the onion model is given in Figure \ref{fig:onion}.

The first layer of the model directly encasing the product is \textbf{Our System}. It encompasses the designed and developed product (i.e. the platform and its instances) and the human parties that directly interface with the product. The first group of these stakeholders is the \emph{Employee Developing and Maintaining} implementations of the platform. They interact directly with scaffolding and frameworks provided by the core platform. Some explanations of the onion model place developers in the outer layer of the model (the wider environment), since after development they no longer interface with the product unless they remain involved in a maintenance capacity. However, developers of a platform instantiation interact with the framework directly provided by the core platform. Therefore, their importance will be emphasized by placing them in the system layer of the model. The second role in the system layer is the \emph{Normal Operator}. These operators receive information from the product directly and interact with subsequent systems and operational support employees to effect change. More specifically, this entails changes to the application under investigation or reports regarding the long-term performance of the application intended for managers and employees higher up in the organization.

The second layer of the model is the \textbf{Containing System}. It contains stakeholders that are heavily invested in the performance and benefits of the product, but do not interact with it directly on a regular basis. Two such stakeholder roles were identified. The first is the \emph{Support and Maintenance Operator} of the application observed by the platform. A stakeholder analysis of the application under investigation would place these operators in the first layer of the model. However, since they do not (necessarily) directly interface with the support platform, they are placed in the second layer of the model for this analysis. They are however heavily invested in the performance and results of the platform, since identified problems and deficiencies can direct their efforts toward maintaining and improving their own application. The second role in this layer is the \emph{Sales Person} of the application under investigation. Again, this regards a sales person of the application under investigation, not of the support platform. The task of a sales person is to convince potential clients to employ a developed product. Performance guarantees are an important part of a sales pitch held by this stakeholder. Therefore, employees of sales departments benefit hugely from known, concrete and stable QoS metrics.

The third layer of the model is the \textbf{Wider Environment}. This final layer contains stakeholders that do not sentiently interface with the product and are not heavily or conscientiously interested in its execution or performance, but are affected by it to some degree. The first stakeholder role in this category is the \emph{Financial Benefactor}. This entity is not heavily invested in the development and daily routine of the system, but does benefit financially from it. This role applies to investors, companies and other business units that are not concerned with the technical upkeep of the product, but do benefit from the gained revenue or cost-efficient measures provided by the product. Closely related with this is the \emph{Political Benefactor}. This benefactor does not directly reap monetary benefit from the solution, but does gain political benefit from it. This can apply to both stakeholders in public office or private business by improving their position in their respective markets. The final stakeholder is the \emph{General Public}. Members of the public do not interface with the platform in any capacity, but can benefit heavily from it. For example, many WSN and IoT applications are deployed in smart city management \cite{example_smart_city} and industry4.0 \cite{example_industry}. Though deployment of dependable IoT technologies in these fields require initial investments, in the long term these technologies can improve efficiency, reducing costs and prizes. Therefore, guaranteed uptime and low resource usage can benefit the consumer, without them realizing it. Though the benefit to singular consumers is relatively small, due to the huge size of the public at large this amounts to an incredible benefit.

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{resources/img/onion.png}
\caption{Visual depiction of application of onion stakeholder model}
\label{fig:onion}
\end{figure}

\section{Commonality/variability analysis}
\label{sec:back:cv_analysis}
In order to design for the problem domain it will require conceptualization. The problem domain(s) will be conceptualized by means of a commonality/variability analysis (C/V analysis). Whereas this analysis is usually performed during the process of system decomposition in product line engineering, it can also be employed to identify common and varying concepts in a problem domain. This analysis identifies the commonalities (invariants) that may be assumed fixed and may be depended upon and the variations in the problem domain which will need to be accounted for by the solution.

J. Coplien et al \cite{cv_analysis} describes the process of a commonality/variability analysis in five steps.
\begin{enumerate}
\nospace
\item Establish the scope: the collection of objects under consideration.
\item Identify the commonalities and variabilities.
\item Bound the variabilities by placing specific on each variability.
\item Exploit the commonalities.
\item Accommodate the variabilities.
\end{enumerate}

The performed conceptualization of the problem domain will mostly focus on step 2 in which a list of common definitions, shared commonalities and variabilities will be provided. Also, steps 4 and 5 will be combined by formulating a list of requirements for intended solution, based on the identified commonalities and accounting for the found variabilities

\section{Distributed computation technologies}
This section will discuss some distributed technologies and concepts that will be evaluated and used during the design of the development platform (Chapter \ref{ch:architecture}).
\label{sec:back:tech}
\subsection{Monolith vs. micro-component}
The first decision to make is the high-level architecture to adopt. The first option for which is to implement the platform as a monolithic software system. The benefit of such a system is that it keeps the solution as simple as can be. This is reflected by a famous proverb of Edsger Dijkstra: ``Simplicity is a prerequisite for reliability'' \cite{dijkstra}. This simplicity entails a better understanding of the product by any future contributor or user, without the need to consult complex, detailed documentation. However, monolithic software products have been known to be difficult to maintain. The reason for this is that code evolution becomes more difficult as development progresses and changes and additions are made to the code base. Additionally, monolithic software systems are notoriously difficult to scale and balance \cite{mono_vs_micro}.

Converse to the monolith is the micro-component architecture. It consists of a multitude of smaller components that are functionally distinct. These components communicate to one another through a underlying message distribution system. By functionally encapsulating the application into distinct modules, an inherent separation of concerns is achieved. This in turn reduces entanglement and improves the application's capacity for evolution. Micro-components are more flexible than monoliths, allow for better functional composition, are easier to maintain and are much more scalable \cite{mono_vs_micro}. Additionally, distributed cloud computing solves some of the tenacious obstacles in IoT's, such as the constraint computational and storage capacity \cite{benefits_cloud_to_iot}. 

\subsection{Apache Storm}
Apache Storm is a micro-component streaming library especially designed for scalability and separation of concerns. It achieves distributed computation by partitioning the stages of computation. It separates stages of computation in distinct processors performing a portion of the global process. These processors are composed into a topology. This topology specifies which processors communicate to which other processors using Storm's inherent message broker. By breaking up the computation, different stages can be distributed among machines and duplicated if required. Processors are specified and executed completely separately and communicate to one another with messages. This messaging is provided by an internalized messaging system and handles are provided by the platform in order to emit and receive messages.

The Storm platform consists of three chief concepts.
\begin{description}[style=nextline]
\nospace
\item[Spouts] Nodes that introduce data in the system,
\item[Bolts] Nodes that perform some computation or transformation on data, and
\item[Topology] An application-level specification of how nodes are connected and messages distributed.
\end{description}
A topology can be configured such that a spout/bolt can emit messages to any other bolt. However, some remarks must be made. Firstly, though spouts/bolts can be connected to multiple bolts, each connection must be specified as an explicit one-to-one mapping. This is converse to many other distributed messaging architectures, in which components subscribe or produce to an addressed channel (topic) that acts as a shared message buffer. Secondly, though the topology is distributed among a cluster, the application is initiated as a single program on the master node. Consequently, the entire application topology must be specified before run-time and the topology cannot be altered or attributed during execution. Such alteration will require a redeployment of the topology and reexecution of the application.

\subsection{Message brokers}
%\subsubsection{Native HTTP}
%The Hypertext Transport Protocol (HTTP) \cite{def:http} is a [onmiskenbaar] communication standard this is widely employed in internet communications. It is well-documented and familiar to almost every industry professional, which should [ease] implementation and maintenance. Aside of maintainability HTTP is very versitile, which should ensure that it meets the needs for our system. However, this versitiliy stems from the barebone definition of the protocol. [TODO afmaken]. Additionally, HTTP routing is performed based on the IP address and port of the target process. This requires any sending component to know all its listener components, requiring either direct IP-based subscription or a discovery/lookup service. 
By employing a micro-component architecture (without an inherent messaging system), a communication technology for components to communicate to each other is required. This approach employs a service to which producers write messages to a certain topic. Consumers can subscribe to a topic and subsequently read from it. This obscures host discovery, since a producer need not know its consumers or vice versa. The routing is instead performed by the message service. The following will explore the two widely used message broker services in the industry.

\subsubsection*{RabbitMQ}
RabbitMQ \cite{web:rabbitmq} is a distributed open-source message broker implementation based on the Advance Message Queue Protocol. It performs topic routing by sending a message to an exchange server. This exchange reroutes the message to a server that contains the queue for that topic. A consumer subscribed to that topic can then retrieve it by popping it from the queue. Finally, an ACK is returned to the producer indicating that the message was consumed. The decoupling of exchange routers and message queues allows for custom routing protocols, making it a versatile solution. RabbitMQ operates on the \emph{competing consumers} principle, which entails that only the first consumer to pop the message from the queue will be able to consume it. This results in an \emph{exactly once} guarantee for message consumption. This makes it ideal for load-balanced micro-component applications, because it guarantees that a deployment of identical services will only process the message once. It does however make multi-casting a message to multiple consumers difficult.

\subsubsection*{Apache Kafka}
Conversely, Apache Kafka \cite{web:kafka} distributes the queues itself. Each host in the cluster hosts any number of partitions of a topic. Producers then write to a particular partition of the topic, while consumers will receive the messages from all partitions of a topic. Because a topic is not required to reside on a single host, it allows load balancing of individual topics. This does however cause some QoS guarantees to be dropped. For instance, message order retention can no longer be guaranteed for the entire topic, but only for individual partitions. Kafka, in contrast to RabbitMQ's competing consumers, operates on the \emph{co-operating consumers} principle. It performs this by, instead of popping the head of the queue, a pointer is retained for each individual consumer. This allows multiple consumers to read the same message from a queue, even at different rates. The topic partition retains a message for some time or maximum number of messages in the topic, allowing consumers to read a message more then once. Ensuring that load-balanced processes only process a message once is also imposed on the consumer by introducing the notion of consumer groups. These groups share a common topic pointer, which ensures that the group collectively only consumes a message once. This process does not require an exchange service, so Kafka does not employ one. This removes some customization of the platform, but does reduce some latency. Lastly, Kafka does not feature application level acknowledgement, meaning that the producer cannot perceive whether its messages are consumed.

\subsection{Distributed processing}
\subsubsection{MapReduce}
MapReduce \cite{mapreduce} is a distributed computing framework. It operates by calling a \emph{mapper} function on each element in the dataset, outputting a set of key-value tuples for each entry. All tuples are then reordered and grouped as sets of tuples with a common key. The key-value sets are then distributed across machines and a \emph{reduce} function is called to reduce the many individual values into some accumulated data points. The benefit of this framework is that the user need only implement the \emph{map} and \emph{reduce} functions. All other procedures, including tuple distribution and calling the mapper and reducer, are handled by the framework. An example of the algorithm on the WordCount problem is illustrated in Figure \ref{img:mapreduce}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{resources/img/mapreduce.png}
\caption{The overall MapReduce word count process \cite{mapreduce_img}}
%https://www.todaysoftmag.com/article/1358/hadoop-mapreduce-deep-diving-and-tuning
\label{img:mapreduce}
\end{figure}

Though the ease of implementation is very high and the technology is very useful, the algorithm has proved to be comparatively slow. The reason for this is that before and after both the map and reduce phase the data has to be written to a distributed file system. Therefore, though highly scalable, the approach suffers from slow disk writes \cite{mapreduce_vs_spark}. Finally, MapReduce works on large finite datasets. Therefore, the data streams must be processed into batches in order for MapReduce to be applicable.

\subsubsection{Apache Spark (Streaming)}
Apache spark \cite{web:spark} is an implementation of the Resilient Distributed Dataset (RDD) paradigm. It employs a master node which partitions large datasets and distributes it among its slave nodes, along with instructions to be performed on individual data entries. Operations resemble the functions and methods of the Java Stream package \cite{java_stream}

Three sort of operations exist: narrow transformations, wide transformations and actions. \emph{Narrow transformations} are parallel operations that effect individual entries in the dataset and result in a new RDD, with the original RDD and target RDD partitioned equally. Examples of such functions are \emph{map} and \emph{filter}. Because these transformations are applied in parallel and partitioning remains identical, many of these transformations can be performed sequentially without data redistribution or recalling the data to the master. \emph{Wide transformations} similarly are applied on individual dataset entries, but the target RDD may not be partitioned equal to the original RDD. An example of such a transformation is \emph{groupByKey}. Since elements with  he same key must reside in the same partition, the RDD might require reshuffling in order for computation to complete. Finally, Actions, such as \emph{collect} and \emph{count} require the data to be recalled to the master and final calculation is performed locally, resulting in a concrete return value of the process. RDD's provide efficient distributed processing of large datasets, that is easy to write and read. However, careful consideration must be given to the operations and execution chain in order to avoid superfluous dataset redistribution \cite{spark_programming_guide}.

Additionally, the framework does not require disk writes as MapReduce does. Instead, it runs distributed calculations in-memory, thereby vastly improving the overall calculation speed. This does however raises a reliability issue, because if a slave node fails, its state cannot be recovered. Such occurrences are resolved by the master by replicating the part of the dataset from the intermediate result it retained and distributing it among the remaining slave nodes. Because the sequence of transformations is deterministically applied to each individual entry in the dataset any new slave node can continue calculations from the last point the state was persisted \cite{rdd_fault_tolerance}.

Finally however, Apache Spark suffers the same deficit as MapReduce and is performed on finite datasets. Therefore, streams need to be divided in batches in order to perform calculations. Fortunately, such a library exists: Apache Spark Streaming \cite{web:spark_streaming}. It batches input from streams on regular intervals and supplies it to a Spark RDD environment. The time windows can be as small as a millisecond. Therefore, it is not formally real-time, but can achieve near real-time stream processing \cite{dstreams}.

\section{Quality of Information of WSN data}
\label{sec:back:qoi}
In WSNs and IoT applications there is the concept of Quality of Information (QoI). QoI describes parameters depicting quality attributes of information presented by and derived from a system. It is especially applicable to WSNs as they present raw low-level data which is then highly processed by subsequent applications. Therefore, the concept of QoI will be employed to validate and evaluate the processing architecture presented in chapter \ref{ch:architecture}. V. Sachidananda et al \cite{qoi_definition} identify the following attributes describing Quality of Information.
\begin{description}
\nospace
\item[Accuracy] The degree of correctness which provides the level of detail in the deployed network. It is the value which is the close imitation of the real-world value.
\item[Precision] The degree of reproducibility of measured values which may or may not be close (accurate) to real-world value.
\item[Completeness] The characteristic of information which provides all required facts for user during the construction of information.
\item[Timeliness] An indicator for the time needed when the first data sample is generated in the network till the information reaches the target application for decision making.
\item[Throughput] The maximum information rate at which information is provided to the user after raw data collection.
\item[Reliability] The characteristic of information, in which information is free from change or no variation of information from the source to the end application.
\item[Usability] The ease of use of information that is available after raw data collection has undergone processing and can be applied to the application based on user's evolvable requirements.
\item[Certainty] The characteristic of information from the source to the sink with desired level of confidence helping the user for decision making.
\item[Tunability] The characteristic of information, where the information can be modified and undergo processing based on user's evolvable requirements.
\item[Affordability] The characteristic of information to know the cost for measuring, collecting and transporting the data/information. It is the expensiveness of information
\item[Reusability] The characteristic of information, where the information is reusable during its lifetime or as long as it is relevant.
\end{description}
\section{Constraint programming and solving}
\label{sec:back:constraint}
Chapter \ref{ch:rdm} will employ the concept of constraint programming and constraint solvers. The concept of constraint programming encompasses modelling a problem by means of a collection of correlated variables and associated value domains. The relations between variables are captured in a list of constraints. The problem is then solved by finding assignments for each variable with respect to their domains that conform to the specified constraints

An example of a problem modelled as constraint problem is a Sudoku. The model will be a list or matrix of integer variables, with each entry having a domain $\{V_i|1\leq V_i\leq 9\}$. The associated constraint would then be $V_1 \neq V_2$ for every combination of entries $(V_1,V_2)$ in the same row, column or 3-by-3 grid.

Several methods exist in order to solve a combinatorial constraint problem. The first and simplest is to perform a brute force search over the solution space. This would produce the Cartesian product of the domains of all variables ($\prod_{i\in I} D_i$) and test them against the constraints. Candidate solutions are rejected until a valid composition of variable assignments is found. This is however a very inefficient procedure as it has to search though the entire search space without optimization. For large combinatorial problems this search space grows exponentially. For instance, for the sudoku example with 20 values filled in, the solution space has a size of $9^{61}(\approx 1,6\cdot 10^{58})$.

A more efficient search algorithm is presented by backtrack-search. Whereas the brute force approach assigns every variable a value and then checks its validity, the backtrack-search algorithm operates on a subset of the variables assigned. By incrementally assigning values to variables it performs a systematic Depth First Search through the search space. If a partial assignment is determined to violate the set of constraints, the algorithm will reject the entire remainder of that branch of the search tree. In this manner the algorithm optimizes failing variable assignments by attempting to identify them earlier. For the example of the sudoku solver this entails that an assignment of a 3 to a position adjacent to another square with a 3 will immediately halt the exploration of that branch of the search tree, without the need to consider subsequent variable assignments. It will instead backtrack through the tree by rolling back assignments and attempt a different assignment.

The backtrack-search algorithm can be improved upon further by implementing constraint propagation. This technique attempts to prune invalid variable values from the domain before they are assigned by the backtrack-search algorithm. For example if a square in the sudoku is assigned a three, then the effect of this assignment will be propagated by pruning the number 3 from the domains of every entry in the same row, column or 3-by-3 grid. This eliminates inconsistent options that would violate the constraints before they would be assigned. Additionally, the concept of local inconsistency can be extended to variable domains without requiring any assignment. For example, given two variables $V_1$ and $V_2$ with domains $D_1=\{1,2,3\}$ and $D_2=\{2,3,4\}$ and the constraint $V_1 \geq V_2$, then the values 1 and 4 can be pruned from $D_1$ and $D_2$ respectively. For they are inconsistent with any of the values in the opposing domain and can therefore never validate the constraint \cite{constraint_general, constraint_algorithm}.


%\section{Example case}
%\label{sec:example_case}
%Throughout this thesis the solutions will be demonstrated by applying them to a hypothetical case. Though this case may sometimes seem oversimplified and nonsensical, it does provide an elementary example to illustrate all facets of the solutions without overcomplicating the case. This case is expressly not intended to demonstrate the capabilities or utility of the proposed solution. For that purpose, an application to a more complex real-world case will be performed in section \ref{ch:validation}

%The proposed case encompasses an enormous network of low power devices sensing for meteorologically anomalous events. These sensors perform measurements on a regular interval and transmit the measurements to a cell tower to be forward to a back-end application for further processing. For the best results devices should measure and transmit as much as possible. However, since these sensors are not very powerful and employ a limited power supply they will require pacing.

%The behaviour of the sensors is typified by two parameters: the sensing interval and transmission interval. Intuitively, it can be stated that shortening either or both of the intervals will result in more fine grained reporting, but will increase the power consumption of the device. Additionally, over time several types of sensors have been deployed with different power sources. Therefore, the amount of electrical power a sensor can use during a given time needs to be restrained in accordance with the specification of its power source and expected life time. Finally, sensors in areas of high interest will require a shorter polling interval, as to gain the most precise information. However, given that the sensor performs the adequate amount of measurements and does not consume more power than it is specified to use, it should measure and report as much as possible.

%As for monitoring, the most interested metric is the measurement rate averaged over all sensors. Additionally, it is required to pro-actively monitor the trend of the total bandwidth used by the sensor application. The reason for this is that a constant rise in data rates may ultimately violate the data consumption limits agreed upon with network service providers.

%To summarize, a sensor must:
%\begin{itemize}
%\nospace
%\item not consume more power then it is allowed according to its battery specification,
%\item measure at least as much as is specified according to the area of interest it is in, and
%\item generally try to measure and report as much as is allowed by the previous two requirements.
%\end{itemize}
%Additionally, the following data points must be provided:
%\begin{itemize}
%\nospace
%\item The average polling rate, and
%\item whether the data rate of the sensor application rises consistently for a certain amount of time.
%\end{itemize}

%In order for the server to determine the intended behaviour of the device and calculate the level of service provided by the application, the following data to be provided to the monitoring application:
%\begin{itemize}
%\nospace
%\item the required measurement rate,
%\item the maximum power provided by the power source,
%\item the measurement rate of the sensor device, and
%\item the bandwidth used by the sensor 
%\end{itemize}
%Each of these data points stipulates the behaviour of a single sensor at a certain instant. Notice that some data points are normally inferred from raw basic data by auxiliary processes (e.g. required measurement rate). For simplification of the demonstrations these processes are omitted and these parameters are presumed known as a message enters the monitoring application.


