\newcommand{\rdmid}{1}
\chapter{Resource Distribution Model}
\section{Requirements}
In this section we will investigate the requirements for the [method of] the RDM. We will achieve this by performing an commonality/variability analysis \cite{var_invar}. This will reveal what the common features are on which we may depend and the variation for which we will need to account for.
\subsection{Commonality/variablity analysis}
\subsubsection{Definitions}
\begin{description}
\item[Resource:] Any measurable/calculable parameter of a system
\item[Resource constraint:] A constraint imposed on a resource.
\item[Component:] Any physical or hypothetical entity that can consume or produce a resource
\item[Quality of Service (QoS):] Parameters which indicate the level of service of a system according to some heuristic function.
\end{description}
\subsubsection{Commonalities}
\begin{enumerate}[label=C\rdmid .\arabic*]
\item Any resource can be consumed or offered by a component
\item A resource can be produced or consumed by multiple components
\item Resources are scarce. I.e. the amount produced must exceed the amount consumed.
\item \label{c:res_transf} Resources are correlated and can converted into one another.
\end{enumerate}

\subsubsection{Variabilities}
\begin{enumerate}[label=V\rdmid .\arabic*]
\item \label{v:obvious} Obviously, we cannot predict all resources, constraints and components that might be used.
\item \label{v:micr_macro} Resources of a system can be modelled on a micro-scale or macro-scale.
\begin{itemize}
\item A micro scale (e.g. a single sensor) entails concrete, palpable parameters.
\item A macro-scale (e.g. an entire WSN application) entails accumulated, theoretical parameters
\end{itemize}
\item \label{v:nr_optimizer} A system can have multiple resources as QoS indicators
\item \label{v:granularity} short term resource usage (e.g. interval of seconds) requires a different granularity than long term resource usage (e.g. interval of days).
\item \label{v:measure_vs_derive} Some resources are directly measurable and thus known for a certain moment of measurement. However, some resources are derived and calculated using other resource values. \cite{feature_model}
\item \label{v:state} Most resource values differ depending on system's measured state
\item \label{v:function} Some resource values differ depending on a specific system function
\end{enumerate}

\subsection{Requirements}
\begin{enumerate}[label=R\rdmid .\arabic*]
\item \label{r:main} The model should represent resource distribution in a system
\item \label{r:transform} Resources should be able to be transformed into other resources (many-to-many)
\item \label{r:resource_types} The model should account for the fact that the value of a resource can originate from different sources. These sources are the following (accompanied with an example):
\begin{description}
\item[constant] a predefined value specified on development time (e.g. initial battery capacity),
\item[measured] a value specified as observed on run time (e.g. percentage of battery capacity left),
\item[calculated] derived from measured values (e.g. runtime left),
\item[variable] any value or a calculation depending on specific system function (e.g. power usage).
\end{description}
\item \label{r:optimizer} Each model should have one, and only one, resource that is associated with a heuristic QoS function.
\item \label{r:constraint} A model should contain constraints that describe the limitations of interconnected resources.
\item \label{r:calculable}Given a resource distribution model, constant-valued resources and measurements, for each combination of values for variable resources, a value should be able to be evaluated for each calculated resource
\item \label{r:solvable} Given a calculable  resource distribution model (\ref{r:calculable}), a set of resource constraints and an optimizer function; an optimal, valid appointment for each variable resource value should be able to be solved efficiently.
\end{enumerate}

\subsection{Justification}
%TODO write

\section{State-of-the-art}
Work regarding modelling resource distribution has been performed in several studies. An elementary example of such research are the studies of Ammar et al\cite{rum_basis_2}. Through their efforts they laid the ground work for representing entities interconnected by shared resources. This UML-based model was one of the first examples of such a representation using formal methods and tools. Another example of early research is the study performed by Seceleanu et al\cite{rum_basis_89}. This study focussed on modelling resource utilization in embedded systems using timed state machines. The transitions in these automata were attributed resource costs to model the consumption of resources for remaining in a state or transitioning to another. Resource consumption and performance can then be calculated and analysed according to the paths taken in this model.
A continuation of this work was performed by Malakuti et al\cite{steven-te-brinke}. They combined the methods of the previous authors by provisioning the modelled system components with their own state machines. These state machines model the resources and services that are offered and required by the components. By analysing these component models as composite state machines, model checking tools (such as UPAAL\cite{web:upaal}) can be used to analyse and evaluate the performance of the system under investigation as a whole.

\section{Solution}
\subsection{Solution options}
These efforts have produced methods of representing components connected by shared resources. Especially the notation of Malakuti et al\cite{steven-te-brinke} which is both intuitive and descriptive. We will therefore continue to use this notation.
however these models are all focussed on components that are self-aware of their resource usage and performance. Instead, we are interested in off-site analysis of interconnected resources and accumulated performance of a composite system. Our focus is therefore alternatively more resource-centred. It is concerned how production and consumption of a resource is interconnected, with components serving as secondary [elements] merely specifying how these resources are converted into other resources. Therefore a resource-centred adaptation of this framework might be more suitable for our problem.
%TODO meer
%TODO deficit state of art

Secondly, there is the issue of how to [represent] a Resource Utilization Model (RUM)\cite{steven-te-brinke}, the model for variable behaviour of components. Previous studies \cite{rum_basis_89, steven-te-brinke} have used timed automata to represent behaviour cycles. This allows for automated tools to calculate a runtime schedule in levels of granularity. However the high level of granularity comes at the cost of efficiency. When we shorten the time intervals for the automata, then solvers require additional computational resources and time. This might force a problem on resource constraint devices or applications that require the solver algorithm to run many times for a multitude of devices. Additionally, we need to consider that a model contains multiple components specified by RUM's. For these models a valid, optimal RUM needs to be determined. In this case RUM's might influence each other, which implies that for different compositions of these models, the individual models need to be re-calculated. %TODO validate

An alternative approach is to model the RUM as a set of static parameters. A component then has multiple RUM's representing different modes of execution. This is achieved by averaging the behaviour for that mode of execution, which would otherwise be modelled by a single timed automata. This comes at great cost of granularity, since the RUM's now only describe some static, long-term behaviours. However it significantly improves the complexity of the search space. For this approach timed automata is no longer a sensible technology since the element of time intervals has been eliminated. Instead the problem is a pure decision problem\cite{decision_problem}. The only problem to be solved is to find a suitable RUM for each modelled component. The search space of a decision problem can be explored with a simple brute force search, exploring all options and compositions. However more effectively, combinatorial problems can often be solved with constraint solvers. The problem is easily transposed to a constraint problem with the resources as model, resource constraints as constraints and the RUM's as variables for the components. With the many solution strategies described in \ref{subsec:constraint} available for different types of problems, a suitable solver should be able to be found or developed.

\subsection{Solution choices}
With careful consideration the following choices for the solution implementation have been made. For modelling we chose to adapt the framework of Malakuti et al\cite{steven_te_brinke}, by emphasizing on resources and introducing some new features. The components will still exist in the model, but will merely serve the function of connecting two resources to one another. Another adaptation is the existence of multiple RUM's for a component, which allows injection of different methods of operation and calculation of the optimal system functionality.

As for how to model the RUM, we chose to reduce the complexity of the system by modelling variable resource usage with static parameters. The strongest advocate for this choice is the fact of the focus for this research: large IoT applications. In an IoT monitoring platform the task of determining optimal device function will need to be performed repeatedly for many sensor devices. Additionally, devices in most large scale IoT applications [refs!!!] only send and receive data a few times per day. Therefore high granularity is not of grave importance because the feedback-control cycle is not that short. 

With the fact that a component can have more than one mode of operation and the choice of static parameters for those functions, makes constraint solvers most suitable as means to solve the model. We will however adapt the search algorithm to conclude not only the valid compositions but the optimal solution, given some heuristic function.

\section{Design}
\subsection{Model}
As stated we will model resource distribution using an extended [version] of the model by Malakuti et al\cite{steven_te_brinke}. The chief adaptations in our model are:
\begin{enumerate}
\item the inclusion of a single explicitly defined optimised resource,
\item simpler RUM`s,
\item the existence of multiple RUM`s for a single component, and
\item constraints defining valid resource interconnection
\begin{enumerate}
\item implicit constraints enforcing availability: $R_{offered} >= R_{consumed}$
\item additional constraints specified by developer
\end{enumerate}
\end{enumerate}

A graphic representation of the adapted meta-model can be found in figure \ref{fig:component}. A complete UML-diagram for the meta-model can be found in Appendix \ref{app:rum_uml}. To illustrate the application of this meta-model, an example of an instantiation of the model can be found in \ref{fig:rdm_cpu_radio}. In essence the model is a collection of \emph{Resources} and \emph{Components}. Each of these resources can be connected to components by means of a \emph{ResourceInterface} and a \emph{ResourceFunction}. 
\begin{figure}
\centering
  \includegraphics[width=0.3\linewidth]{resources/img/component.pdf}
  \caption{Notation of an RDM component with RUM's}
  \label{fig:component}
\end{figure}
\begin{figure}
\hrule
\begingroup\centering
  \includegraphics[width=\linewidth]{resources/img/rdm_cpu_radio.pdf}\endgroup \\ \\
  \noindent Constraints: \\
$c_1: cycles_{clock} >= cycles_{CPU}$ \\
$c_2: power_{power\_source} >= power_{CPU}+power_{Radio} $ \\ \\
\noindent Optimize:\\$max(QoS)$\\
\hrule
\caption{Example instatiation of the RDM meta-model with a CPU and a radio}
  \label{fig:rdm_cpu_radio}
\end{figure}

%TODO insert pics
\subsubsection{Resource}
A resource is an entity describing a parameter of a system. This can be a measured parameter (e.g. battery capacity left or throughput), but can also describe a derived parameter (e.g. service time left). Each resource is identified by it's name and has a unit associated with it. By aggegating the ResourceInterfaces of a resource the amount of the resource produced and consumed can be collected and analysed.

\subsubsection{Component}
Any entity producing, consuming and converting a resource is represented by a component. A component can therefore be a physical entity such as a radio module or a battery or a hypothetical entity such as a QoS calculator executing a heuristic function. A component [contains] a ResourceFunction of each Resource it is connected to.
A [special] case of the Component is the ModelComponent. This class inherits all functionality of the ordinary Component, but its ResourceFunctions are extracted from one of its RUM's. Each RUM describes the parameters during one mode of operation of the components. This allows runtime analysis of variable behaviour as effect of different functionalities.

\subsubsection{ResourceInterface}
Resources and components are connected through resource interfaces. A ResourceInterface can be one of three types:
\begin{description}
\item[Offer] Indicating that the component produces an amount of the resource,
\item[Consume] Indicating that the component consumes an amount of the resource,
\item[Calculate] Special consume relation. This connection supplies 100\% of the offered resource, without formally consuming any amount. This relation is used to further calculate with the offered value, without it impacting the constraints of the resource. For example a QoS indicator that is ``consumed'' by a general QoS calculation.
\end{description}
Each interface has a value specifying the amount of the resource produced or consumed by the component. This value is repeatedly set and evaluated at runtime by executing a ResourceFunction.

\subsubsection{ResourceFunction}
The value of a ResourceInterface is determined by a ResourceFunction. This function constist of a function that takes a double array as argument and with a double as result, and an array of resource identifiers to fill the input array respectively. ResourseInterfaces can [compactly] be instantiated using lambda expressions and varargs. E.g.:
\begin{lstlisting}[language=java, frame=single, numbers=left, tabsize=4, basicstyle=\small]
ResourceFunction totalServiceTime = new ResourceFunction(
	(x)->x[0]+x[1], yearsServed, yearsLeft
);
\end{lstlisting}

To model the [gewenste] behaviour of the model we introduce a set of \textbf{Requirements} and an \textbf{Optimizer}.
\subsubsection{Requirement}
A resource can have any number of Requirements function as constraints that limit the possible values of [variation] of that resource. The standard built-in requirement for every resource is the \emph{OfferConsumeGTE} requirement which enforces that the amount produced needs to be greater or equal than the amount consumed. Additional requirements \emph{OfferConsumeEQ} and \emph{RangeRequirment} are supplied that respectively require the exact amount offered to be consumed and the amount offered or consumed to be within certain bounds. Finally the abstract class Requirement can be extended by a developer to specify any tailored requirement.
\subsubsection{Optimizer}
To [assertain] the heuristic [grade] of a RDM with a [gevulde] RUM configuration we introduce the Optimizer. The Optimizer is an extended class of Resource of which exaclty one must exist in an RDM. The optimizer takes the evaluated offered amount of the Resource and calculates a score. This score is a value on a comparative scale of which a higher value entails a more optimal solution. Supplied are the \emph{MinMaxOptimizer} which evaluates that the amount offered must have a minimal or maximal (specifiable) value and the \emph{ApproxOptimizer} which evaluates that the resource must have an amount offered as close to a specified value as possible. However, custom implementations of the Optimizer can again be made by developers.

\subsubsection{RdmMessage}
Finally, to supply the model with the state of the system under investigation, we pose the RdmMessage. The RdmMessage is provisioned using values measured from the system and injected in the model, after which the appropriate resource values are evaluated accordingly. Technically, a simple mapping from a resource name to a measured value value would do for this purpose, but this mapping is wrapped in an object to support future [expansions] of the object.

\subsection{Solving the model}
With the model well-esteblished, we can now try and solve the model. From requirement \ref{r:solvable} we find the goal of solving the model is to find a composition of RUM's such that:
\begin{enumerate}
\item each ModelComponent has exaclty one RUM associated with it,
\item all resource constraints are satisfied, and
\item the optimizer function of the optimized resource has the highest value.
\end{enumerate}
The first and second requirement implies constraint solvers as an applicable technology[. Since] they are effective in finding a valid solution for a constraint decision problem. However, the third requirement [implies] that we do not want to find any valid solution, but the optimal valid solution. In order to do that we need to consider \emph{every} valid solution to the problem and compare how they compare [heuristicly]. This entails a [brute force] search approach through the entire search[-]space of RUM compositions. We can however use constraint solver [paradigms] to preventively reduce the search space as we search through it.

The way we do this is by employing backtrack search. In a simple brute force search we would calculate all RUM compositions and for each composition we provision the full model and evaluate it. Instead we will iteratively select a component and one of its models. We will then not provision the entire model, but inject the selected model in the chosen ModelComponent. Consequently we calculate only those variables we can resolve with the information currently represented by the model. We then evaluate the resource constraints. Given an incomplete model any constraint can have one of three statuses:
\begin{itemize}
\item satisfaction,
\item failure, or
\item uncertain
\end{itemize}
for consequent assingments of unprovisioned components.

If a constraint evaluates to \emph{satisfied} it will be pruned and not [evaluated] in the remainder of this [branch] of the search [tree], since we know it will always succeed. If a constraint is \emph{uncertain} we keep it, since we do not know its [state] for each and every future [state]. If even a single constraint \emph{fails} we know the remainder of this branch of the search tree will never be valid. Therefore we backtrack through the tree by partially rolling back model assignment. We then select a different model for the same component or a different component entirely and repeat the algorithm [ref to algorithm]. This way we do not re-evaluate constraints we already know the state of and do not [visit] paths we know will not satisfy the constraints. Given that we encounter unsatisfactory options early in the tree, this will eliminate large [parts] of the search tree. An example of this algorithm on the example posed in Figure \ref{fig:rdm_cpu_radio} is given in Figure \ref{fig:search_cpu_radio}. This application illustrates that using this algorithm, we eliminate a significant portion of the search tree. This is due to early constraint failure detection in the \emph{CPU=high\_cpu} banch of the tree.
\begin{figure}
\input{tree_cpu_radio}
\label{fig:search_cpu_radio}
\caption{Application of backtrack search on RDM of Figure \ref{fig:rdm_cpu_radio}}
\end{figure}

\section{Discussion/evaluation}
\subsubsection{Static model}
As stated before we chose to use a [flat] representation of resource utilization by [modelled] components. We chose this in order [greatly] reduce the complexity of the problem and this allows the model to be evaluated [within reasonable] time. We came to this conclusion after early experiments with timed automata. In this experiment we modelled a minimal system with one component with three RUM's. When analysed using time intervals of one week over a life span of ten years, it took over one minute to calculate the optimal [path]. Granted, this was performed on a laptop machine and not a high-powered server. When deployed on a server with sufficient [calculatory] resources the time to calculate will be reduced. This is however counteracted by the fact for a WSN application this calculation needs to be repeated for thousends of sensors. When we compare this performance to the [flat] models which can evaluate more complex models (e.g. 3 components, 5 RUM's each) within seconds, we must eliminate timed automata as valueble runtime technology. However, this does not eliminate automata entirely. Automata can still be used to model the [run cycles] of parts of a system in order to develop [static] RUM's.

%TODO
(dis)advantages van explicit model

\subsubsection{Solver libraries}
When developing this [solution] we chose to implement the constraint solving algorithm ourselves, instead of employing existing libraries such as Choco Solver [ref] or OptaPlanner [ref]. 

The Choco Solver is a powerful solver which not only employs backtrack search, but also constraint propagation to eliminate [failing] search paths before [early]. However, while powerfull, it has only limited support for real numbers \cite{ibex-choco}. Additionally it [was] very difficult to [omzetten] the user defined models and arithmatic expressions to the modelling mechanism of the solver. Requiring that either the user need to input the model and calculations in the complex modeling mechanism of the Choco Solver or for us to write a [omzetter] to rewrite easy to write user input to Choco Solver code.

Another examined library is the OptaPlanner. The OptaPlanner is a modelling framework for constraint problems and exells in use cases involving planning and resource allocation. It also enables object injection which would be greatly suitable for injecting our RUM's in components. However the OptaPlanner is strictly a modelling framework and does not employ advanced solving techniques [available] in the field of constraint programming. It performs a brute force depth-first search over the search space (cartetic product of all RUM compositions) [running] a single code block which evaluates all constraints. It consequently can not reduce the search space by eliminating failing branches and redundant constraints.

Finally, the implementation of backtrack search does not differ [that] much from the implementation of depth-first search. Additionlly, this approach allows us to incorporate domain knowledge into our custom algorithm and enables us to [take shortcuts], further reducing the runtime required. This reduces the comperative benifit of employing a constraint solver library and eventually led us to develop our own solver implementation.

\subsubsection{Constraint propagation}
A [tactic] mentioned before is the concept in constraint solvers of constraint propagatin. Constraint propagation explores the search space the same [way] as back track search. However, each variable assingment $V_1$ all other variable domains are reduced by pruning all variables assingments $VA_2$ that are incompatible with $VA_1$. For example for the example of Figure \ref{fig:rdm_cpu_radio}: if \emph{CPU=High\_CPU} is assigned, \emph{Radio=High\_radio} is pruned because it would require more power than is actually produced. This eliminates inconsistent variables without the need of assigning them, thereby reducing the search space even more efficient than native backtrack search. This is easily implemented with integer/real variables that are interconnected with constraints. However, in our model the variables are not integer/real domains, but objects with integer/real variables. This doesn't make constraint propagation impossible, but does complicated it.

Secondly, the interconnected nature of our problem [reduces] the benefits recieved from constraint propagation. To illustrate this consider the following example. A resource \emph{R} is connected to a set of producers \emph{P} and a set of consumers \emph{C}, for each the amount produced or consumed is variable. The amount produced by any component \emph{x} is denoted by $R_x$. The availability constraint on \emph{R} can then be written as:
$$\sum_{p \in P}R_p \geq \sum_{c \in C}R_c$$
Which entails for any $c1 \in C$: 
$$R_{c1} \leq (\sum_{p \in P} R_p - \sum_{c2 \in (C-c1)} R_{c2})$$
In order to be able to prune any value from the domain of consumer \emph{c1}, we need to assign all producers in order to determine a reliable upper bound.\footnote{Future assignments of the other consumers may be disregarded since they will never raise the upper bound for $R_{c1}$, only lower it.} This requires the search to be already at least $|P|$ levels deep, reducing the part of the tree possibly eliminated. Even then, we are only able to prune the values for which:
$$R_{c1} > \sum_{p \in P} R_p$$
Which might not be many since a single consumer must consume more of a resource than produced by all producers combined. When other consumers get a value assigned we may be able to prune more values, but this requires even more variable assignments. This [problem] is agrevated when $R_p$ is a derived value calculated using a number of other resources. Values for all these resources must be known in order to calculate the value of $R_p$.

To conclude, the part of the tree that is eliminated is limited since we are all ready halfway into the search tree and the chance that a value is eliminated halfway in the tree is very small. Therefore no further effort was made to incorporate constraint propagation or other look-ahead strategies in the solver.

\section*{TODO/work in progress}
include historic information. Model is now painfully one-dimentional and does not [prevent] local minimum/maximum.
%\subsection{discussion}
%always possible to convert state to optimizable (hypothetical) heuristic resource [search def:heuristic]
%short vs long term
%	solved by explicitly focussing on long term. By choice, long rtt and long lifetime.
%	allows collapsing states to single state (single variable)
%	guarentees solvability
%measure vs derive
%	- every internal resource needs to be calculable from only eventual external, measurable resources %(transitive)
%	- no cyclical calculations
	





%What to represent
%	Components, calculators
%	resources
%		requirements
%		optimizable
%	resource distribution
%What inputs
%What outputs
%what actions




