%algemene introductie
%methode
%	conceptualisation of problem domain
%		(jim coplin? var/com)
%probelem analysis
%req
%technieken 
%etc.
 

\newcommand{\rdmid}{2}
\chapter{Resource Distribution Model}
\label{ch:rdm}
\section{Objective of the model}
The aim of the Resource Distribution Model (RDM) is to comprehend the distribution, conversion and requirements of resource parameters in a system, in accordance with research question RQ6-8. The suggested target usage of these models is to allow automated analysis and optimization of the system under investigation. Therefore we require a detailed model with explicitly defined entities and relations. Only then can the model be employed by automated tools and algorithms. The research questions [related] to this chapter are 

This will be performed by first exploring the problem domain. With the definitions and concepts of the problem domain identified, we will compose a list of requirements for the proposed model. With these requirements in mind we will explore contemporary resource modelling solutions and evaluate them on the applicability to our requirements. We will then explain how the selected technologies will be adapted for our purposes. Subsequently, we will describe our model in detail and exemplify how we intend to use the model in order to calculate the optimal performance of a modelled system. We will conclude this chapter with an evaluation of the proposed modelling technique.

\section{Conceptualization of the problem domain}
\label{sec:cv_analysis}
In this section we will investigate the problem domain in order to eventually determine the requirements for the model. Again, we will achieve this by performing a commonality/variability analysis (section \ref{sec:back:cv_analysis}) of the problem domain, determining the definitions, common features and variations in our problem domain.

\subsubsection{Definitions}
We will first establish some terms we will be using throughout the C/V analysis and the remainder of this chapter. 
\begin{description}[style=nextline]
\nospace
\item[Resource] Any measurable/calculable parameter of a system
\item[Resource constraint] A constraint imposed on a resource.
\item[Component] Any physical or hypothetical entity that can consume or produce a resource
\item[Resource Utilization Model (RUM)] A model depicting how much of a resource is produced or consumed by a component. Each instance of such a model is internalized by a singular component.
\item[Resource Distribution Model (RDM)] A model depicting components are interconnectively connected by resources. This global model encompasses all Resources, Components, their relations and behaviour. 
\item[Quality of Service (QoS)] Particular resource parameters that are indicative of the level of service provided by a system.
\end{description}
\subsubsection{Commonalities}
Following the definitions we will now identify commonalities that appear throughout the problem domain. These assumed features allow us to focus our efforts and allows more expressive specification of assumed concepts.
\begin{enumerate}[label=C\rdmid .\arabic*]
\nospace
\item \label{c:1resource_multiplex} A resource can be consumed or offered by multiple components.
\item \label{c:2component_multiplex} A component can produce or offer multiple resources.
\item \label{c:3scarce} Resources are scarce, i.e. the amount produced must exceed the amount consumed.
\item \label{c:4res_transf} Resources are correlated and can be converted into one another.
\item \label{c:5optimize} Resource amounts can be used to objectively compare functionality of a system.
\end{enumerate}

\subsubsection{Variabilities}
With the commonalities established we will now consider the variabilities in the problem domain. These variations cannot be specified specifically in the model, but instead require proper abstraction in the model, to be implemented when a instantiation of the model is performed.
\begin{enumerate}[label=V\rdmid .\arabic*]
\nospace
\item \label{v:1obvious} Though all use cases agree on the above commonalities, we cannot predict all resources, components, constraints and interconnection that can occur.
\item \label{v:2micro_macro} Resources of a system can be modelled on a micro-scale or macro-scale.
\begin{itemize}
\nospace
\item A micro-scale (e.g. a single sensor device) entails concrete, palpable parameters.
\item A macro-scale (e.g. an entire WSN application) entails accumulated, theoretical parameters
\end{itemize}
\item \label{v:3nr_optimizer} A system can have multiple resources as QoS indicators
\item \label{v:4granularity} Short term resource usage (e.g. interval of seconds) requires a different granularity than long term resource usage (e.g. interval of days).
\item \label{v:5measure_vs_derive} Some resources are directly measurable and thus known for a certain moment of measurement. However, some resources are derived and calculated using other resource values. \cite{feature_model}
\item \label{v:6state} Most resource values differ depending on system's measured state
\item \label{v:7function} Some resource values/usages differ depending on a specific system function
\item \label{v:8rum} Given a system's state some system functions are better suited than others.
\end{enumerate}

\section{Requirements for the proposed model}
With the common and variable features of the problem domain established we can formulate a list of requirements that need to be incorporated in the solution. In this section we will therfore identify the requirements for the projected model. We will first provide a full list of the identified requirements before justifying them according to the C/V analysis of section \ref{sec:cv_analysis}.
\subsection{Requirements}
\begin{enumerate}[label=R\rdmid .\arabic*]
\nospace
\item \label{r:1main} The model should represent resource distribution in a system
\item \label{r:2transform} Resources should be able to be transformed into other resources (many-to-many)
\item \label{r:3resource_types} The model should account for the fact that the value of a resource can originate from different sources. The identified sources are the following:
\begin{description}
\nospace
\item[constant] a predefined value specified on development time (e.g. initial battery capacity),
\item[measured] a value specified as observed on run time (e.g. percentage of battery capacity left),
\item[calculated] derived from measured values (e.g. runtime left),
\item[variable] any value or a calculation depending on specific system function (e.g. power usage).
\end{description}
\item \label{r:4optimizer} Each model should have one, and only one, resource that is associated with a heuristic QoS function.
\item \label{r:5constraint} A model should contain constraints that describe the limitations of interconnected resources.
\item \label{r:6calculable}Given a resource distribution model, constant-valued resources and measurements, for each combination of values for variable resources, a value should be able to be evaluated for each calculated resource
\item \label{r:7solvable} Given a calculable  resource distribution model (\ref{r:6calculable}), a set of resource constraints and an optimizer function; an optimal, valid appointment for each variable resource value should be able to be solved efficiently.
\end{enumerate}

\subsection{Justification of identified requirements}
Table \ref{table:justification} demonstrates how the proposed requirements account for the determined variety, based on the observed commonalities. Most requirements can easily be traced  to the variety it strives to restrain. An exception is requirement \ref{r:4optimizer}, which states that one resource is used to optimize the QoS. This is seemingly contradicted by \ref{v:3nr_optimizer} which states that multiple resources can be indicative of the level of QoS. This is however explained with use of \ref{c:4res_transf}. This commonality states that resources can be transformed into one another (many-to-many). It can therefore be inferred that it is possible to transform multiple QoS markers into a single optimizable, meta-physical resource, according to some heuristic QoS function.

Evidently omitted from the justification table is variation \ref{v:4granularity}. This is due to that a this variety has far-reaching consequences for the implementation of the model. Therefore a choice has been made to focus on modelling of resource distribution during large time intervals. This choice will elaborated in section \ref{sub:choices}.
\begin{table}
\centering
\begin{tabular}{|l|l|} \hline
Variety & Requirements \\ \hline
\ref{v:1obvious} & \ref{r:1main}, \ref{r:3resource_types}, \ref{r:5constraint}		\\ \hline
\ref{v:2micro_macro} & \ref{r:1main}, \ref{r:3resource_types} 	\\ \hline
\ref{v:3nr_optimizer} & \ref{r:2transform}, \ref{r:4optimizer} 	\\ \hline
\ref{v:5measure_vs_derive} & \ref{r:2transform}, \ref{r:3resource_types} \\ 	\hline
\ref{v:6state} & \ref{r:3resource_types} 	\\ \hline
\ref{v:7function} & \ref{r:3resource_types}, \ref{r:6calculable} 	\\ \hline
\ref{v:8rum} & \ref{r:4optimizer}, \ref{r:5constraint}, \ref{r:7solvable} 	\\ \hline
\end{tabular}
\hspace{24px}
\begin{tabular}{|l|l|} \hline
Requirement & Commonalities \\ \hline
\ref{r:1main} & \ref{c:1resource_multiplex}, \ref{c:2component_multiplex}	\\ \hline
\ref{r:2transform} & \ref{c:4res_transf}	\\ \hline
\ref{r:3resource_types} &	\\ \hline
\ref{r:4optimizer} & \ref{c:4res_transf}, \ref{c:5optimize} 	\\ \hline
\ref{r:5constraint} & \ref{c:3scarce}	\\ \hline
\ref{r:6calculable} & \ref{c:4res_transf}	\\ \hline
\ref{r:7solvable} & \ref{c:3scarce}, \ref{c:5optimize}	\\ \hline
\end{tabular}
\caption{Justification of requirements by variety and commonalities}
\label{table:justification}
\end{table}

\section{State of the art of the solution domain}
In this section we will explore the current techniques and technologies in the field of resource modelling. We will first identify the state of the art of the field, before evaluating their applicability according to our established requirements. Finally we will declare and defend the choices we made before adapting the technologies in the next section.

\subsection{State of the art}
Work regarding modelling resource distribution has been performed in several studies. Elementary examples of such research are the studies of Ammar et al\cite{rum_basis_2}. Through their efforts they laid the ground work for representing entities interconnected by shared resources. This UML-based model was one of the first examples of such a representation using formal methods and tools. Another example of early research is the study performed by Seceleanu et al\cite{rum_basis_89}. This study focussed on modelling resource utilization in embedded systems using timed state machines. The transitions in these automata were attributed resource costs to model the consumption of resources for transitioning to a state of remaining in one. Resource consumption and performance over time  can then be calculated and analysed according to the paths taken in this model.

A continuation of this work was performed by Malakuti et al\cite{steven-te-brinke}. They combined the methods of the previous authors by provisioning the modelled system components with their own state machines. These state machines model the resources and services that are offered and required by the components. By analysing these component models as composite state machines, model checking tools (such as UPAAL\cite{web:upaal}) can be used to analyse and evaluate the performance of the investigated system as a whole.

\subsection{Evaluation of the solution domain}
These efforts have produced methods of representing components connected by shared resources. Especially the notation of Malakuti et al\cite{steven-te-brinke}, which is both intuitive and descriptive. We will therefore continue to use this notation.

however these models are all focussed on components that are self-aware of their resource usage and performance. Instead, we are interested in off-site analysis of interconnected resources and accumulated performance of a composite system. Our focus is therefore alternatively more resource-centred. It is concerned how production and consumption of a resource is interconnected. Components only serve as secondary elements, merely specifying how these resources are converted into other resources. Therefore a resource-centred adaptation of this framework might be more suitable for our problem.

Secondly, there is the issue of how to represent a Resource Utilization Models (RUM)\cite{steven-te-brinke}, the model for variable behaviour of components. Previous studies \cite{rum_basis_89, steven-te-brinke} have used timed automata to represent behaviour cycles. This allows for automated tools to calculate a runtime schedule in high levels of granularity. However the high level of granularity comes at the cost of efficiency. When we shorten the time intervals for the automata, entailing higher granularity, then solvers require additional computational resources and time to execute. This might force a problem on resource constraint devices or applications that require the solver algorithm to run many times for a multitude of devices. Additionally, we need to consider that a model contains multiple components specified by RUM's. For these models a valid, optimal RUM composition needs to be determined. In this case RUM's might influence each other, which implies that for different compositions of these models, the individual models need to be re-calculated.

An alternative approach is to model the RUM as a set of static parameters. A component then has multiple RUM's representing different modes of execution. This is achieved by averaging the behaviour for that mode of execution, which would otherwise be modelled by a single timed automaton. This comes at great cost of granularity, since the RUM's now only describe a few static, predefined long-term behaviours. However it significantly improves the complexity of the search space. For this approach timed automata is no longer a sensible technology since the element of time intervals has been eliminated. Instead the problem is a pure decision problem\cite{decision_problem}. The only problem to be solved is to find a suitable RUM for each modelled component. The search space of a decision problem can be explored with a simple brute force search, exploring all options and compositions. However more effectively, combinatorial problems can often be solved with constraint solvers. The problem is easily transposed to a constraint problem with the RDM as model, resource constraints as constraints and the RUM's as variables for the components. With the many solution strategies described in \ref{sec:back:constraint} available for different types of problems, a suitable solver should be able to be found or developed.

\subsection{Choices of employed solutions}
\label{sub:choices}
With careful consideration the following choices for the solution implementation have been made. For modelling we chose to adapt the framework of Malakuti et al\cite{steven_te_brinke}, by emphasizing on resources and introducing some new features. The components will still exist in the model, but will merely serve the function of connecting two resources to one another. Another adaptation is the existence of multiple RUM's for a component, which allows injection of different methods of operation and calculation of the optimal system functionality.

As for how to model the RUM, we chose to reduce the complexity of the system by modelling variable resource usage with static parameters. The strongest advocate for this choice is the fact of the focus for this research: large IoT applications. In an IoT monitoring platform the task of determining optimal device function will need to be performed repeatedly for many sensor devices. Additionally, devices in most large scale IoT applications  only send and receive data a few times per day\cite{refs over size zoeken}. Therefore high granularity is not of grave importance because the feedback-control cycle is not that short. 

The fact that a component can have more than one mode of operation and the choice of static parameters for those functions, makes constraint solvers most suitable as means to solve the model. We will however complement the search algorithm to conclude not only the valid compositions but the optimal solution, given some heuristic function.

\section{Design of the Resource Distribution Model}
This section will be dedicated to exerting the adaptations made to the previously described modelling efforts. We will first depict how we defined our model in both broad terms and specific modelling entities, followed by how we intend to solve the model by calculating the optimal configuration of variables in the model.
\subsection{The model}
As stated we will model resource distribution by extending the model by Malakuti et al\cite{steven_te_brinke}. The chief adaptations in our model are:
\begin{enumerate}
\nospace
\item the inclusion of a single explicitly defined optimised resource,
\item RUM`s with static resource values,
\item the existence of multiple RUM`s for a single component, and
\item constraints defining valid resource interconnectivity:
\begin{enumerate}
\nospace
\item implicit constraints enforcing availability: $R_{offered} \geq R_{consumed}$
\item additional explicit constraints specified by developer
\end{enumerate}
\end{enumerate}

A graphic representation of the adapted meta-model can be found in figure \ref{fig:component}. In essence the model is a collection of \emph{Resources} and \emph{Components}. Each of these resources can be connected to components by means of a \emph{ResourceInterface} and a \emph{ResourceFunction}. 
\begin{figure}
\centering
  \includegraphics[width=0.3\linewidth]{resources/img/component.pdf}
  \caption{Notation of an RDM component with RUM's}
  \label{fig:component}
\end{figure}

\subsubsection{Resource}
A resource is an entity describing a parameter of a system. This can be a measured parameter (e.g. battery capacity or throughput), but can also describe a derived parameter (e.g. service time left). Each resource is identified by it's name and has a unit associated with it. By aggregating the ResourceInterfaces of a resource the amount of the resource produced and consumed can be collected and analysed.

\subsubsection{ResourceInterface}
Resources and components are connected through resource interfaces. A ResourceInterface can be one of three types:
\begin{description}
\nospace
\item[Offer] Indicating that the component produces an amount of the resource,
\item[Consume] Indicating that the component consumes an amount of the resource,
\item[Calculate] Special consume relation. This interface supplies 100\% of the offered resource, without formally consuming any amount. This relation is used to further calculate with the offered value, without it impacting the constraints of the resource. For example a QoS indicator that is ``consumed'' by a general QoS calculation.
\end{description}
Each interface has a value specifying the amount of the resource produced or consumed by the component. This value is repeatedly set and evaluated at runtime by executing a ResourceFunction.

\subsubsection{Component}
Any entity producing, consuming and converting a resource is represented by a component. A component can therefore be a physical entity such as a radio module or a battery or a hypothetical entity such as a QoS calculator executing a heuristic function. A component possesses a ResourceFunction of each Resource it is connected to.

A special subtype of the Component is the ModelComponent. This class inherits all functionality of the ordinary Component, but its ResourceFunctions are extracted from one of its RUM's. Each RUM describes the parameters during one mode of operation of the components. This allows runtime analysis of variable behaviour as effect of different functionalities.

\subsubsection{ResourceFunction}
The value of a ResourceInterface is determined by a ResourceFunction. It consists of a function that takes a double array as argument and has a double as result, and an array of resource identifiers. Runtime solvers or engines will then fill the input array according to the resource identifiers in order to execute the function. ResourseInterfaces can be compactly instantiated using lambda expressions and VarArgs. E.g.:
\begin{lstlisting}[language=java, frame=single, numbers=left, tabsize=4, basicstyle=\small]
ResourceFunction totalServiceTime = new ResourceFunction(
	(x)->x[0]+x[1], "yearsServed", "yearsLeft"
);
\end{lstlisting}

To model the intended behaviour of the model we introduce a set of \emph{Requirements} and an \emph{Optimizer}.
\subsubsection{Requirement}
A resource can have a number of Requirements as constraints that limit the possible values of variation for that resource. The standard built-in requirement for every resource is the \emph{OfferConsumeGTE} requirement which enforces that the amount produced needs to be greater or equal than the amount consumed. Additional requirements \emph{OfferConsumeEQ} and \emph{RangeRequirement} are specified, that respectively require the exact amount offered to be consumed and the amount offered or consumed to be within certain bounds. Finally the abstract class \emph{Requirement} can be extended by a developer to specify any tailored requirement.
\subsubsection{Optimizer}
To ascertain the heuristic score of an RDM with an injected RUM configuration we introduce the Optimizer. The Optimizer is an extended class of Resource of which exactly one must exist in an RDM. The optimizer takes the evaluated offered amount of this resource and calculates a score. This score is a value on a comparative scale on which a higher value implies a more optimal solution. Specified are the \emph{MinMaxOptimizer} which evaluates that the amount offered must have a minimal or maximal value and the \emph{ApproxOptimizer} which evaluates that the resource must have an amount offered as close to a specified value as possible. However, custom implementations of the Optimizer can again be made by developers.

\subsubsection{RdmMessage}
Finally, to supply the model with the state of the system under investigation, we pose the RdmMessage. The RdmMessage is provisioned using values measured from the system and injected into the model, after which the appropriate resource values are evaluated accordingly. Technically, a simple mapping from a resource identifier to a measured value would suffice for this purpose, but this mapping is wrapped in an object to support future evolution.


\subsection{Demonstration by example case}
To illustrate the application of this meta-model, an example of an instantiation of the model can be found in figure \ref{fig:rdm_cpu_radio}. This instantiation is based on the example case described in section \ref{sec:example_case}. In this depiction we can see the power supply (battery) which emits a resource `power', measured in milliwatts. The actual value of this variable is instantiated based on the input message (illustrated by dotted arrow) since, as described earlier, specifications of power supplies vary in our example case. This power is consequently consumed by the device's CPU and radio module. This entails an implied resource constraint $c_1$, which enforces that the joint power consumption of the CPU and radio may not exceed the power produced by the power supply. Both the CPU and Radio can run on a high or low performance model, with the high models having aggravating consequences for the power consumption and the offered number of measurements and throughput respectively. The amount of measurements per second offered by the CPU is subsequently consumed in full by the \emph{Measurement requester}. This component simulates a resource request on the sensor devices and imposes a requisite on the minimum amount of measurements performed and offered by the CPU, as formulated by constraint $c_2$. The request value is based on a parameter supplied by the input message. Finally both the amount of measurements and bandwidth provided are supplied to the \emph{QoS calculator} which uses the information to calculate a singular value depicting the level of QoS provided by the model instantiation. This value is used to determine the optimal variable composition given a validated set of competing models. In closing, emphasis should be given to the interfaces of the QoS calculator. These interfaces are not regular \emph{consume} relations but \emph{calculate} relations. This entails that the QoS calculator has full knowledge of the amounts offered, without affecting the consumption of those resources. This ensures that the behaviour of the QoS calculator has no influence on the validity of the model by impacting constraint $c_2$.

\begin{figure}
\hrule
\begingroup\centering
  \includegraphics[width=\linewidth]{resources/img/rdm_cpu_radio.pdf}\endgroup \\ \\
  \noindent Constraints: \\
$c_1: power_{power\_supply} >= power_{CPU}+power_{radio} $ \\ 
$c_2: measuremnts_{CPU} >= measurements_{measurement\_requester}$ \\ \\
\noindent Optimize:\\$max(QoS)$\\
\hrule
\caption{Example instantiation of the RDM meta-model according to the example case}
  \label{fig:rdm_cpu_radio}
\end{figure}

\subsection{Computing an optimal model assignment}
With the model well established we can now try and solve the model. From requirement \ref{r:7solvable} we find the goal of solving the model is to find a composition of RUM's such that:
\begin{enumerate}
\nospace
\item each ModelComponent has exactly one RUM associated with it,
\item all resource constraints are satisfied, and
\item the optimizer function of the optimized resource has the highest value.
\end{enumerate}
The first and second requirement imply constraint solvers as an applicable technology, since they are effective in finding a valid solution for a constraint decision problem. However, the third requirement entails that we do not want to find just any valid solution, but the \emph{optimal} valid solution. In order to do that we need to consider every valid solution to the problem and compare how they compare heuristically. This entails a full brute force search approach through the entire search space of RUM compositions. We can however use constraint solver paradigms to preventively reduce the search space as we search through it.

The way we do this is by employing backtrack search. In a simple brute force search we would calculate all RUM compositions (Cartesian product) and for each composition we provision the full model and evaluate it. Instead we will iteratively select a component and one of its models. We will then not provision the entire model, but inject only the selected model in the chosen component. Consequently, we set the values for variables for which we can resolve a definite value, given the current state of the model. We then evaluate the resource constraints. Given an incomplete model any constraint can have one of three statuses:
\begin{itemize}
\nospace
\item satisfaction,
\item failure, or
\item uncertain
\end{itemize}
for all consequent assignments of unprovisioned components.

If a constraint evaluates to \emph{satisfied} it will be pruned from the constraint set and will not evaluated for the remainder of this branch of the search tree, since we know it will always succeed. If a constraint is \emph{uncertain} we keep it, since we do not know its status for each and every future state. If even a single constraint \emph{fails} we know the remainder of this branch of the search tree will never be valid. Therefore we backtrack through the tree by partially rolling back model assignments. We then select a different model for the same component or a different component entirely and repeat the algorithm. This way we do not recheck constraints we already know the state of and do not evaluate paths we know will not satisfy the constraints. The full original algorithm is given in Listing \ref{alg:backtrack-search}. 

Given that we encounter unsatisfactory options early in the tree, this will possibly eliminate large parts of the search tree. An example of the application of this algorithm on the example previously posed (Figure \ref{fig:rdm_cpu_radio}) is given in Figure \ref{fig:search_cpu_radio}. This example is executed based on an RdmMessage with values $\{measureRateRequired=8,\ powerBySpecification=16\}$. This application demonstrates that using this algorithm, we eliminate a significant portion of the search tree. This is due to early constraint failure detection in the \emph{CPU=high\_cpu} banch of the tree.

\input{resources/listings/backtrack-search}
%label=alg:backtrack-search

\begin{figure}
\input{resources/img/tree_cpu_radio}
\caption{Application of backtrack search on RDM of Figure \ref{fig:rdm_cpu_radio}}
\label{fig:search_cpu_radio}
\end{figure}


\section{Discussion of the proposed model}
We will conclude this chapter by endorsing some of the choices that were made for our proposed model. 
\subsubsection{Static model}
As stated before we chose to use a static representation of resource utilization by ModelComponents. We chose this in order greatly reduce the complexity of the problem and this allows the model to be evaluated within a reasonable amount of time. We came to this conclusion after early experiments with timed automata. In this experiment we modelled a minimal system with one component with three RUM's. When analysing the model using time intervals of one week over a life span of ten years, it took over one minute to calculate the optimal traversal of the automaton. Granted, this was performed on a laptop machine and not a high-powered server. When deployed on a server with sufficient calculatory resources the time to calculate will be reduced. However, this is counteracted by the fact for a WSN application this calculation needs to be repeated for thousands of sensors. When we compare this performance to that of the static models, which can evaluate more complex models within seconds, we must eliminate timed automata as viable solution for real-time analysis. However, this does not eliminate automata entirely. Automata can still be used to model the fine grained run cycles of parts of a system in order to develop generalized static RUM's.


\subsubsection{Solver libraries}
When developing this solution we chose to implement the constraint solving algorithm ourselves, instead of employing existing libraries such as Choco Solver\cite{web:choco} or OptaPlanner\cite{web:opta}. 

The Choco Solver is a powerful solver which not only employs backtrack search, but also constraint propagation to eliminate failing search paths before assigning them. However, while powerfull, it has only limited support for real intervals \cite{ibex-choco}. Additionally it proved very difficult to convert the user defined models and arithmetic expressions to the modelling mechanism of the solver. Requiring the user to either input the model and calculations in the complex modelling mechanism of the Choco Solver or for us to develop a compiler to rewrite the easy to write user input to Choco Solver code.

Another examined library is the OptaPlanner\cite{optaplanner}. The OptaPlanner is a modelling framework for constraint problems and excels in use cases involving planning and resource allocation. It also enables object injection which would be greatly suitable for injecting our RUM's into components. However the OptaPlanner is strictly a constraint modelling framework and does not employ advanced solving techniques developed in the field of constraint programming. It performs a brute force depth-first search over the search space (Cartesian product of all RUM compositions) running a single code block which evaluates all constraints. It consequently can not reduce the search space by eliminating failing branches and redundant constraints. Therefore it lacks the means to solve the problem efficiently

Finally, the implementation of backtrack search does not differ much from the implementation of depth-first search. Additionally, developing our own solver allows us to incorporate domain knowledge into our custom search algorithm, further reducing the runtime required. This reduces the comparative benefit of employing a constraint solver library and eventually led us to develop our own solver implementation.

\subsubsection{Constraint propagation}
A technique in constraint solvers mentioned before is the concept of constraint propagation \cite{ref-zoeken}. Constraint propagation explores the search space the in the same manner as backtrack search. However, for each variable assignment $V_1$ all other variable domains are preventatively reduced by pruning all variable assignments $V_2$ that are incompatible with $V_1$. For example in the example of Figure \ref{fig:rdm_cpu_radio}: if \emph{CPU=High\_CPU} is initially assigned, \emph{Radio=High\_radio} is pruned because it would require more power than is actually produced. This eliminates inconsistent variables without the need of assigning them, thereby reducing the search space even more effectively than native backtrack search. This is easily implemented with integer/real variables that are interconnected with constraints. However, in our model the variables are not integer/real domains, but objects with integer/real variables. This doesn't make constraint propagation impossible, but does complicated it greatly.

Secondly, the interconnected nature of our problem can impede the benefits received from constraint propagation. To illustrate this consider the following example: resource \emph{R} is connected to a set of producers \emph{P} and a set of consumers \emph{C}, for each the amount produced or consumed is variable. The amount produced or consumed by any component \emph{x} is denoted by $R_x$. The availability constraint (more must be produced than is consumed) on \emph{R} can then be written as:
$$\sum_{p \in P}R_p \geq \sum_{c \in C}R_c$$
Which entails for any consumer $c1 \in C$: 
$$R_{c1} \leq \left(\sum_{p \in P} R_p - \sum_{c2 \in (C-c1)} R_{c2}\right)$$
In order to be able to prune any value from the domain of consumer \emph{c1}, we need to assign all producers in order to determine a reliable upper bound\footnote{Future assignments of the other consumers may be disregarded since they will never raise the upper bound for $R_{c1}$, only lower it.}. This requires the search to be already at least $|P|$ levels deep, reducing the part of the tree possibly eliminated. Even then, we are only able to prune the values for which:
$$R_{c1} > \sum_{p \in P} R_p$$
Which might not be many since a single consumer must consume more of a resource than produced by all producers combined, in order for the constraint to fail. When other consumers get a value assigned we may be able to prune values more easily, but this requires even more variable assignments. This problem is aggravated when $R_p$ is a derived value calculated using a number of other resources. Values for all these resources must be known in order to calculate the value of $R_p$.

To conclude, the part of the tree that is eliminated with constraint propagation is limited since we are already halfway into the search tree and, additionally, the chance that a value is eliminated halfway in the tree is very small. Therefore no further effort was made to incorporate constraint propagation or other look-ahead strategies in the solver.


%include historic information. Model is now painfully one-dimentional and does not [prevent] local minimum/maximum.

%\subsection{discussion}
%always possible to convert state to optimizable (hypothetical) heuristic resource [search def:heuristic]
%short vs long term
%	solved by explicitly focussing on long term. By choice, long rtt and long lifetime.
%	allows collapsing states to single state (single variable)
%	guarentees solvability
%measure vs derive
%	- every internal resource needs to be calculable from only eventual external, measurable resources %(transitive)
%	- no cyclical calculations
	





%What to represent
%	Components, calculators
%	resources
%		requirements
%		optimizable
%	resource distribution
%What inputs
%What outputs
%what actions




