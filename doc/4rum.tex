%algemene introductie
%methode
%	conceptualisation of problem domain
%		(jim coplin? var/com)
%probelem analysis
%req
%technieken 
%etc.
 

\newcommand{\rdmid}{2}
\chapter{Resource Distribution Model}
\label{ch:rdm}
\section{Objective of the model}
The aim of the Resource Distribution Model (RDM) is to comprise the distribution, conversion and restriction of resource parameters in a system, in accordance with research question RQ6-8. The suggested target usage of these models is to allow automated analysis and optimization of the system under investigation. Therefore, a detailed model with explicitly defined entities and relations is required. Only then can the model be employed by automated tools and algorithms. The research questions related to this chapter are \ref{rq:idenfity_model}--\ref{rq:solve_model}.

This will be performed by first exploring the problem domain. With the definitions and concepts of the problem domain identified, a list of requirements for the proposed model will be composed. With these requirements in mind, the contemporary resource modelling solutions will be explored and evaluated on the applicability to the requirements. Afterwards, the adaptations to the selected technologies will be explained. Subsequently, the conceived model will be described in detail. To assist the understanding of the model, it will be exemplified by application to the described example case (Section \ref{sec:example_case}). This chapter will be concluded with an evaluation of the proposed modelling technique.

\section{Conceptualization of the problem domain}
\label{sec:cv_analysis}
This section will investigate the problem domain in order to eventually determine the requirements for the model. Again, this will be achieved by performing a commonality/variability analysis (section \ref{sec:back:cv_analysis}) of the problem domain, determining the definitions, common features and variations in the problem domain.

\subsubsection{Definitions}
First, some terms that will be used throughout the C/V analysis and the remainder of this chapter will be stated. Following that, the common features and variations in the problem domain.
\begin{description}[style=nextline]
\nospace
\item[Resource] A measurable/calculable parameter of a system
\item[Resource constraint] A constraint imposed on a resource due to scarcity.
\item[Component] A physical or hypothetical entity that can consume or produce a resource
\item[Resource Utilization Model (RUM)] A model depicting how much of a resource is produced or consumed by a component. Each instance of such a model is internalized by a single component.
\item[Resource Distribution Model (RDM)] A model depicting how components are interconnectively connected by resources. This global model encompasses all Resources, Components, their relations and behaviour. 
\item[Quality of Service (QoS)] Particular resource parameters that are indicative of the level of service provided by a system.
\end{description}
\subsubsection{Commonalities}
Following the definitions, the commonalities that appear throughout the problem domain will be asserted. These assumed features allow the efforts to be focussed and allows a more expressive specification of assumed concepts.
\begin{enumerate}[label=C\rdmid .\arabic*]
\nospace
\item \label{c:1resource_multiplex} A resource can be produced or consumed by multiple components.
\item \label{c:2component_multiplex} A component can produce or consume multiple resources.
\item \label{c:3scarce} Resources are scarce, i.e. the amount produced must exceed the amount consumed.
\item \label{c:4res_transf} Resources are correlated and can be converted into one another (many-to-many).
\item \label{c:5optimize} Resource parameters can be used to objectively compare functionality of a system.
\end{enumerate}

\subsubsection{Variabilities}
With the commonalities established, the variabilities in the problem domain will be considered. These variations cannot be specified expressively in the mode. Instead they require proper abstraction in the model, to be implemented when a instantiation of the model is achieved.
\begin{enumerate}[label=V\rdmid .\arabic*]
\nospace
\item \label{v:1obvious} Though all use cases agree on the above commonalities, not all resources, components, constraints and interconnection that can occur can be predicted \cite{qos_challenges}.
\item \label{v:2micro_macro} Resources of a system can be modelled on a micro-scale or macro-scale.
\begin{itemize}
\nospace
\item A micro-scale (e.g. a single sensor device) comprises concrete, palpable parameters.
\item A macro-scale (e.g. an entire WSN application) comprises derived, theoretical parameters
\end{itemize}
\item \label{v:3nr_optimizer} A system can have a variety of resources as QoS indicators \cite{qos_challenges}.
\item \label{v:4granularity} Short term resource usage (e.g. interval of seconds) requires a different granularity than long term resource usage (e.g. interval of days).
\item \label{v:5measure_vs_derive} Some resources are directly measurable and thus known at a certain moment of measurement. However, some resources are derived and calculated using other resource values.
\item \label{v:6state} Resource values can differ depending on system's measured state
\item \label{v:7function} Resource values differ depending on a specific system operational strategy
\item \label{v:8rum} Given a system's state some operational strategies are better suited than others.
\end{enumerate}

\section{Requirements for the proposed model}
With the common and variable features of the problem domain established, the following section will formulate a list of requirements that need to be incorporated in the solution. First a full list of the identified requirements will be provided, before justifying them according to the C/V analysis of the previous section.
\subsection{Requirements}
\begin{enumerate}[label=R\rdmid .\arabic*]
\nospace
\item \label{r:1main} The model should represent resource distribution in a system
\item \label{r:2transform} Resources should be able to be transformed into other resources (many-to-many)
\item \label{r:3resource_types} The model should account for the fact that the value of a resource can originate from different sources. The identified sources are the following:
\begin{description}
\nospace
\item[constant] a predefined value specified on development time (e.g. initial battery capacity),
\item[measured] a value specified as observed on run time (e.g. percentage of battery capacity left),
\item[calculated] derived from measured values (e.g. runtime left),
\item[variable] any value or a calculation depending on specific system function (e.g. power usage).
\end{description}
\item \label{r:4optimizer} Each model should have one, and only one, resource that is associated with a heuristic QoS function.
\item \label{r:5constraint} The model should contain constraints that describe the limitations of bounded resources.
\item \label{r:6calculable}Given a resource distribution model, constant-valued resources and measurements, for each combination of values for variable resources, a value should be able to be evaluated for each calculated resource
\item \label{r:7solvable} Given a calculable  resource distribution model (\ref{r:6calculable}), a set of resource constraints and an optimizer function; an optimal, valid appointment for each variable resource value should be able to be solved efficiently.
\end{enumerate}

\subsection{Justification of identified requirements}
Table \ref{table:justification} demonstrates how the proposed requirements account for the determined variety, based on the observed commonalities. Most requirements can intuitively be traced  to the variety it strives to restrain. An exception is requirement \ref{r:4optimizer}, which states that one resource is used to optimize the QoS. This is seemingly contradicted by \ref{v:3nr_optimizer}, which states that multiple resources can be indicative of the level of QoS. This is however explained with use of \ref{c:4res_transf}. This commonality states that resources can be transformed into one another (many-to-many). It can therefore be inferred that it is possible to transform multiple QoS markers into a single optimizable, derived resource according to some heuristic QoS indicator function.

Evidently omitted from the justification table is variation \ref{v:4granularity}. This is due to that a this variety has far-reaching consequences for the implementation of the model. Therefore a choice has been made to focus on modelling of resource distribution during large time intervals. This choice will elaborated in section \ref{sub:choices}.
\begin{table}
\centering
\begin{tabular}{|l|l|} \hline
Variety & Requirements \\ \hline
\ref{v:1obvious} & \ref{r:1main}, \ref{r:3resource_types}, \ref{r:5constraint}		\\ \hline
\ref{v:2micro_macro} & \ref{r:1main}, \ref{r:3resource_types} 	\\ \hline
\ref{v:3nr_optimizer} & \ref{r:2transform}, \ref{r:4optimizer} 	\\ \hline
\ref{v:5measure_vs_derive} & \ref{r:2transform}, \ref{r:3resource_types} \\ 	\hline
\ref{v:6state} & \ref{r:3resource_types} 	\\ \hline
\ref{v:7function} & \ref{r:3resource_types}, \ref{r:6calculable} 	\\ \hline
\ref{v:8rum} & \ref{r:4optimizer}, \ref{r:5constraint}, \ref{r:7solvable} 	\\ \hline
\end{tabular}
\hspace{24px}
\begin{tabular}{|l|l|} \hline
Requirement & Commonalities \\ \hline
\ref{r:1main} & \ref{c:1resource_multiplex}, \ref{c:2component_multiplex}	\\ \hline
\ref{r:2transform} & \ref{c:4res_transf}	\\ \hline
\ref{r:3resource_types} &	\\ \hline
\ref{r:4optimizer} & \ref{c:4res_transf}, \ref{c:5optimize} 	\\ \hline
\ref{r:5constraint} & \ref{c:3scarce}	\\ \hline
\ref{r:6calculable} & \ref{c:4res_transf}	\\ \hline
\ref{r:7solvable} & \ref{c:3scarce}, \ref{c:5optimize}	\\ \hline
\end{tabular}
\caption{Justification of requirements by variety and commonalities}
\label{table:justification}
\end{table}

\section{State of the art of the solution domain}
This section will explore the current techniques and technologies in the field of resource modelling. First, state of the art of the field will be identified, before evaluating their applicability according to the established requirements. Finally, the choices made before adapting the technologies in the next section will be declared and defended.

\subsection{State of the art}
Work regarding modelling resource distribution has been performed in several studies. Elementary examples of such research are the studies of Ammar et al \cite{rum_basis_2}. Through their efforts they laid the ground work for representing entities interconnected by shared resources. This UML-based model was one of the first examples of such a representation using formal representations. Another example of early research is the study performed by Seceleanu et al \cite{rum_basis_89}. This study focussed on modelling resource utilization in embedded systems using timed state machines. The transitions in these automata are attributed costs to model the consumption of resources for transitioning to a state of residing in one. Resource consumption and performance over time  can then be calculated and analysed according to the paths taken in this model.

A continuation of this work was performed by Malakuti et al \cite{steven_te_brinke}. They combined the methods of the previous authors by provisioning the modelled system components with their own state machines. These state machines model the resources and services that are offered and required by the components. By analysing these component models as composite state machines, model checking tools can be used to analyse and evaluate the performance of the investigated system as a whole.

\subsection{Evaluation of the solution domain}
These efforts have produced methods of representing components connected by shared resources. Especially the notation of Malakuti et al \cite{steven_te_brinke}, which is both intuitive and descriptive. Therefore this notation will be adopted. However. the models in these studies focus on components that are self-aware of their resource usage and performance. Instead, the interest is in off-site analysis of interconnected resources and accumulated performance of a composite system. Alternatively, the focus will therefore be more centred around the concept of resources. It is concerned how production and consumption of a resource is interconnected. Components serve as secondary elements, merely specifying how these resources are connected and converted into other resources. Therefore a resource-centred adaptation of this framework might be more suitable.

Secondly, there is the issue of how to represent a Resource Utilization Models (RUM) \cite{steven_te_brinke}, the model for variable behaviour of components. Previous studies have used timed automata to represent behaviour cycles \cite{rum_basis_89, steven_te_brinke}. This allows for automated tools to calculate a runtime schedule in high degree of granularity. However the high level of granularity comes at the cost of efficiency. When the time interval for the automata is shortened, entailing higher granularity, then solvers require additional computational resources and time to execute. This might enforce a complication on resource constraint devices or applications that require the solver algorithm to run many times for a multitude of devices. Additionally, it must be consider that a model contains multiple components specified by RUM's. A composition of such related automata explodes the search space for the composite automaton, reducing the feasibility to calculate them effectively.

An alternate approach is to model the RUM as a set of static parameters. A component then has multiple RUM's representing different modes of execution. This is achieved by averaging the behaviour for that mode of execution, which would otherwise be modelled by a single timed automaton. This comes at great cost of granularity, since the RUM's now only describe a few static, predefined periodical behaviour. However it significantly reduces the complexity of the search space. For this approach timed automata is no longer a suitable technology, since the element of time intervals has been eliminated. Instead the problem is a pure decision problem. The problem to be solved is to find a suitable RUM for each modelled component. 

The search space of a decision problem can be explored with a simple brute force search, exploring all options and compositions. However more effectively, combinatorial problems can often be solved with constraint solvers. The problem is easily transposed to a constraint problem with the RDM as model, resource constraints as constraints and the RUM's as variables for the components. With the many solution strategies described in \ref{sec:back:constraint} available for different types of problems, a suitable solver should be able to be found or devised.

\subsection{Choices of employed solutions}
\label{sub:choices}
With careful consideration the following choices for the solution implementation have been made. For modelling it was chosen to adapt the framework of Malakuti et al \cite{steven_te_brinke} by emphasizing on resources and introducing some new features. The components will still exist in the model, but will merely serve the function of connecting resources to one another. Another adaptation is the existence of multiple RUM's for a component, which allows injection of different methods of operation.

As for how to model the RUM, it was chosen to reduce the complexity of the system by modelling resource usage with fixed mathematical functions. Modelling changeable behaviour is subsequently achieved by providing a component with multiple RUM, detailing different operational strategies. The strongest advocate for this choice is the fact of the focus for this study: large WSN applications. In a WSN monitoring platform the task of determining optimal device function will need to be performed repeatedly for many sensor devices. Additionally, devices in most large scale LPWA applications only communicate data a limited amount of times per day (at most a few hundred)\cite{nbiot_battery_not_suitable, lora_vs_sigfox_boek}. Therefore, high granularity is not of grave importance because the feedback-control cycle is not that short. 

The fact that a component can have more than one mode of operation and the choice of static parameters for those functions, makes constraint solvers most suitable as means to solve the model. However the search algorithm will be complemented to conclude not only the valid compositions but the optimal solution, given some heuristic function.

\section{Design of the Resource Distribution Model}
This section will be dedicated to detailing the resulting model. First the general modelling concepts will be described, before focussing on specific modelling entities. The section will be concluded with an examination of how the optimal RUM configuration of the model is proposed to be deduced.

As stated, resource distribution is modelled by extending the model by Malakuti et al \cite{steven_te_brinke}. The chief adaptations to the model are:
\begin{enumerate}
\nospace
\item RUM`s with static resource values,
\item the existence of multiple RUM`s for a single component,
\item the inclusion of a single explicitly defined optimised resource, and
\item constraints defining valid resource interconnectivity:
\begin{enumerate}
\nospace
\item implicit constraints enforcing availability: $R_{offered} \geq R_{consumed}$
\item additional explicit constraints specified by developer
\end{enumerate}
\end{enumerate}

A graphic representation of the adapted meta-model can be found in figure \ref{fig:component}. In essence the model is a collection of \emph{Resources} and \emph{Components}. Each of these resources can be connected to components by means of a \emph{ResourceInterface} and a \emph{ResourceFunction}. 
\begin{figure}
\centering
  \includegraphics[width=0.3\linewidth]{resources/img/component.pdf}
  \caption{Notation of an RDM component with RUM's}
  \label{fig:component}
\end{figure}

\subsubsection{Resource}
A resource is an entity describing a parameter of a system. This can be a measured parameter (e.g. battery capacity or throughput), but can also describe a derived parameter (e.g. service time left). Each resource is identified by it's name and has a unit associated with it. 

\subsubsection{ResourceInterface}
Resources are interfaced with through ResourceInterfaces. A ResourceInterface can be one of three types:
\begin{description}
\nospace
\item[Offer] Indicating that the component produces an amount of the resource,
\item[Consume] Indicating that the component consumes an amount of the resource,
\item[Calculate] Special consume relation. This interface supplies 100\% of the offered resource, without formally consuming any amount. This relation is used to further calculate with the offered value, without it impacting the constraints of the resource%. For example a QoS indicator that is ``consumed'' by a general QoS calculation.
\end{description}
Each interface has a value specifying the amount of the resource produced or consumed by the component. This value is repeatedly set and evaluated at runtime by executing a ResourceFunction. By aggregating the interfaces of a resource the amount of the resource produced and consumed can be computed and analysed.

\subsubsection{ResourceFunction}
The value of a ResourceInterface is determined by a ResourceFunction. It consists of a function that takes a double array and an array of resource identifiers as argument, and has a double as result. Runtime solvers or engines will then fill the input array, in accordance with the resource identifiers, in order to execute the function. ResourceFunctions are compactly instantiated using lambda expressions and VarArgs. E.g.:
\begin{lstlisting}[language=java, frame=single, numbers=left, tabsize=4, basicstyle=\small]
ResourceFunction totalServiceTime = new ResourceFunction(
	(x)->x[0]+x[1], "yearsServed", "yearsLeft"
);
\end{lstlisting}

\subsubsection{Component}
Any entity producing, consuming and converting a resource is represented by a component. A component can therefore be a physical entity such as a radio module or a battery, or a hypothetical entity such as a QoS calculator executing a heuristic function. A component possesses a ResourceFunction of each Resource it is connected to.

A specific subtype of the Component is the ModelComponent. This class inherits all functionality of the ordinary Component. However, its ResourceFunctions are specified by its RUM's. Each RUM describes the parameters during one mode of operation of the component. This allows runtime analysis of variable behaviour as effect of different performance strategies.

To model and evaluate the intended behaviour of the model a set of \emph{Requirements} and an \emph{Optimizer} are introduced.
\subsubsection{ResouceConstraint}
A resource can have a number of constraints that limit the possible values of variation for that resource. The standard inherent requirement for every resource is the \emph{OfferConsumeGTE} requirement which enforces that the amount produced needs to be greater or equal than the amount consumed. Additional requirements \emph{OfferConsumeEQ} and \emph{RangeRequirement} are specified, that respectively require the exact amount offered to be consumed and the amount offered or consumed to be within certain bounds. Finally the abstract class \emph{Requirement} can be extended by a developer to specify any tailored requirement.

\subsubsection{Optimizer}
The Optimizer is introduced to ascertain the heuristic score of an RDM with a valid RUM configuration. The Optimizer is an extended class of Resource of which exactly one must exist in an RDM. The optimizer takes the evaluated offered amount of this resource and calculates a score. This score is a value on a comparative scale on which a higher value implies a more optimal solution. Specified are the \emph{MinMaxOptimizer} which evaluates that the amount offered must have a minimal or maximal value and the \emph{ApproxOptimizer} which evaluates that the resource must have an amount offered as close to a specified value as possible. However, custom implementations of the Optimizer can be made.

\subsubsection{RdmMessage}
Finally, to supply the model with the state of the system under investigation the RdmMessage is posed. The RdmMessage is provisioned using values measured from the system and injected into the model, after which the appropriate resource functions are evaluated accordingly. Technically, a simple mapping from a resource identifier to a measured value would suffice for this purpose, but this mapping is wrapped in an object to support future evolution.


\subsection{Demonstration by example case}
To illustrate the application of this model an example of an instantiation of the model can be found in figure \ref{fig:rdm_cpu_radio}. This instantiation is again based on the example case described in Section \ref{sec:example_case}. This depiction contains a power supply (battery) which emits a resource `power', measured in milliwatts. The actual value of this variable is instantiated based on the input message (illustrated by dotted arrow). The reason for this is that, as described earlier, specifications of power supplies vary in the example. This power is consequently consumed by the device's CPU and radio module. This entails an implied resource constraint $c_1$, which enforces that the joint power consumption of the CPU and radio may not exceed the power produced by the power supply. Both the CPU and Radio can run on a high or low performance model, with the high models having aggravating consequences for the power consumption and the offered number of measurements and throughput respectively. The amount of measurements per second offered by the CPU is subsequently consumed in full by the \emph{Measurement requester}. This component simulates a resource request on the sensor devices and imposes a requisite on the minimum amount of measurements performed and offered by the CPU, as formulated by constraint $c_2$. The requested value is determined by a parameter supplied by the input message. Finally both the amount of measurements and bandwidth provided are supplied to the \emph{QoS calculator}. It uses these resources to calculate a singular value depicting the level of QoS provided by the model instantiation. This value is used to determine the optimal variable composition given a set of valid models. In closing, emphasis should be given to the interfaces of the QoS calculator. These interfaces are not regular \emph{consume} relations but \emph{calculate} relations. This entails that the QoS calculator has full knowledge of the amounts offered, without affecting the consumption of those resources. This ensures that the behaviour of the QoS calculator has no influence on the validity of the model by impacting constraint $c_2$.

\begin{figure}
\hrule
\begingroup\centering
  \includegraphics[width=\linewidth]{resources/img/rdm_cpu_radio.pdf}\endgroup \\ \\
  \noindent Constraints: \\
$c_1: power_{power\_supply} >= power_{CPU}+power_{radio} $ \\ 
$c_2: measurements_{CPU} >= measurements_{measurement\_requester}$ \\ \\
\noindent Optimize:\\$max(QoS)$\\
\hrule
\caption{Example instantiation of the Resource Distribution Model according to the example case.}
  \label{fig:rdm_cpu_radio}
\end{figure}

\subsection{Computing a valid, optimal model assignment}
With the model well established, its resolvability requires attention. Requirement \ref{r:7solvable} yields that solving the model is to find a composition of RUM's such that:
\begin{enumerate}
\nospace
\item each ModelComponent has exactly one RUM associated with it,
\item all resource constraints are satisfied, and
\item the optimizer function of the optimized resource has the highest value.
\end{enumerate}
The first and second requirement imply constraint solvers as a highly applicable technology, since they are effective in finding a valid solution for a constraint decision problem. However, the third requirement entails that not just any valid solution is requested, but the \emph{optimal} valid solution. In order to do that, every valid solution to the problem needs to be considered and compared how they rank heuristically. This entails a full brute-force search approach through the entire search space of RUM compositions. However, constraint solver paradigms can be used to efficiently traverse the search space.

This is performed by employing backtrack search. A simple brute force search would calculate all RUM compositions (Cartesian product) and for each composition the full model is provisioned and evaluated. Instead backtrack search iteratively selects a component and one of its models. It will then not provision the entire model, but inject only the selected model in the chosen component. Subsequently given the current state of the model, the variables which can be resolved are assigned a definite value. After which the resource constraints are evaluated. Given a partial model assignment, any constraint can have one of three statuses:
\begin{itemize}
\nospace
\item satisfaction,
\item failure, or
\item unresolved
\end{itemize}
for all subsequent assignments of unprovisioned components.

If a constraint evaluates to \emph{satisfied} it will be pruned from the constraint set and will not evaluated for the remainder of this branch of the search tree, for it is known to always succeed. If a constraint is \emph{unresolved} it is kept, since its status is not certain for every future state. If even a single constraint \emph{fails} the remainder of that branch of the search tree will never be valid. Therefore, the algorithm backtracks through the tree by partially rolling back model assignments. A different model is then selected for the same component or a different component entirely and the algorithm is repeated. This ensures that validated constraints are not re-evaluated and invalidated search tree traversals are detected promptly. The full original algorithm is given in Listing \ref{alg:backtrack-search}. 

By rapidly detecting unsatisfactory options in the search tree, large portions of the tree can possibly be eliminated. An example of the application of this algorithm on the example previously illustrated (Figure \ref{fig:rdm_cpu_radio}) is given in Figure \ref{fig:search_cpu_radio}. This example is executed based on an RdmMessage with values $\{measureRateRequired=5,\ powerBySpecification=16\}$. This application demonstrates that using this algorithm eliminates a significant portion of the search tree. This is due to early detection of constraint failure in the \emph{CPU=high\_cpu} branch of the tree.

\input{resources/listings/backtrack-search}
%label=alg:backtrack-search

\begin{figure}
\input{resources/img/tree_cpu_radio}
\caption{Application of backtrack search on RDM of Figure \ref{fig:rdm_cpu_radio}}
\label{fig:search_cpu_radio}
\end{figure}

%TODO every valu as double?
\section{Discussion of the proposed model}
This chapter will be concluded by endorsing some of the choices that were made for the proposed model. 
\subsubsection{Behaviour as static RUM's}
As stated before it was chosen to use a static representation of resource utilization in Resource Utilization Models. This was chosen in order greatly reduce the complexity of the search problem, which allows the model to be evaluated within a reasonable amount of time. This was decided after early experiments with timed automata. In this experiment a minimal system with one component with three RUM's was modelled. When computing the behaviour of the model using time intervals of one week over a life span of ten years, it took over one minute to calculate the optimal traversal of the automaton. Granted, this was performed on a laptop machine and not a high-powered server. When deployed on a machine with elevated computational resources the time to calculate will be reduced. However, this is counteracted by the fact for a WSN application this calculation needs to be repeated for thousands of sensors. When this performance is compared to that of the static models, which can evaluate more complex models within seconds, timed automata must be eliminated as viable solution for real-time analysis. However, this does not eliminate automata entirely. Automata can still be used to model the fine grained runtime behaviour a system in order to abstract generalized static RUM's from it.

\subsubsection{Solver libraries}
When developing this solution a decision was made to implement a custom constraint solving algorithm, instead of employing existing libraries such as Choco Solver \cite{web:choco} or OptaPlanner \cite{web:opta}. 

The Choco Solver is a powerful solver which not only employs backtrack search, but also constraint propagation to eliminate failing search paths before assigning them. However, while powerful, it has only limited support for real intervals \cite{choco_ibex}. Additionally it proved very difficult to convert the user-specified models and ResourceFunction's arithmetic expressions to the modelling mechanism of the solver. Requiring a developer to either input the model and calculations in the complex modelling mechanism of the Choco Solver or for a translator to be developed that compiles the user-defined model to Choco Solver code.

Another examined library is the OptaPlanner \cite{web:opta}. The OptaPlanner is a modelling framework for constraint problems and excels in use cases involving planning and resource allocation. It also enables object injection which would be greatly suitable for injecting RUM's into components. However the OptaPlanner is strictly a constraint modelling framework and does not employ advanced solving techniques developed in the field of constraint programming. It performs a brute force depth-first search over the search space and executes a single code block which evaluates all constraints. It consequently can not reduce the search space by eliminating failing branches and redundant constraints. Therefore it lacks the means to solve the problem efficiently

Finally, developing a custom solver allowed incorporation domain knowledge into the search algorithm, further reducing overhead. This reduces the comparative benefit of employing a constraint solver library and eventually led to the development of a custom solver implementation.

\subsubsection{Constraint propagation}
A technique in constraint solvers mentioned before is the concept of constraint propagation \cite{constraint_general}. Constraint propagation explores the search space in the same manner as backtrack search. However, for each variable assignment $V_1$ all other variable domains are preventatively reduced by pruning all variable assignments $V_2$ that are incompatible with $V_1$. For example in the example of Figure \ref{fig:rdm_cpu_radio}: if \emph{CPU=Low\_CPU} is initially assigned, \emph{Radio=High\_radio} is pruned immediately, because it would require more power than is actually produced. This eliminates inconsistent variables without the need of assigning them, thereby reducing the search space even more effectively than native backtrack search. This is easily implemented with integer/real variables that are interconnected with constraints. However, in the model the variables are not integer/real domains, but objects with integer/real variables. This doesn't make constraint propagation impossible, but does complicated it.

Secondly, the interconnected nature of resources can impede the benefits received from constraint propagation. To illustrate this consider the following complex example: resource \emph{R} is connected to a set of producers \emph{P} and a set of consumers \emph{C}, for each the amount produced or consumed is variable. The amount produced or consumed by any component \emph{x} is denoted by $R_x$. The availability constraint (i.e. amount produced must be more than consumed) on \emph{R} can then be written as:
$$\sum_{p \in P}R_p \geq \sum_{c \in C}R_c$$
Which entails for any consumer $c1 \in C$: 
$$R_{c1} \leq \left(\sum_{p \in P} R_p - \sum_{c2 \in (C-c1)} R_{c2}\right)$$
In order to be able to prune any value from the domain of consumer \emph{c1}, all producers must be assigned. Only then can a concrete upper bound be determined\footnote{Future assignments of the other consumers may be disregarded since they will never raise the upper bound for $R_{c1}$, only lower it.}. This requires the search to be already at least $|P|$ levels deep, reducing the part of the tree possibly eliminated. Even then, only values can be pruned for which:
$$R_{c1} > \sum_{p \in P} R_p$$
Which might not be many since a single consumer must consume more of a resource than produced by all producers combined, in order for the constraint to fail. When other consumers get a value assigned pruning becomes more effective, but this requires even more variable assignments. 
%This problem is aggravated when $R_p$ is a derived value calculated using a number of other resources. Values for all these resources must be known in order to calculate the value of $R_p$.

To conclude, the part of the tree that is eliminated with constraint propagation is limited. for any variable to be pruned the algorithm must already be halfway into the search tree. Furthermore, the chance that a value is eliminated halfway in the tree is very small. Therefore no further effort was made to incorporate constraint propagation or other look-ahead strategies in the solver.


%include historic information. Model is now painfully one-dimentional and does not [prevent] local minimum/maximum.

%\subsection{discussion}
%always possible to convert state to optimizable (hypothetical) heuristic resource [search def:heuristic]
%short vs long term
%	solved by explicitly focussing on long term. By choice, long rtt and long lifetime.
%	allows collapsing states to single state (single variable)
%	guarentees solvability
%measure vs derive
%	- every internal resource needs to be calculable from only eventual external, measurable resources %(transitive)
%	- no cyclical calculations
	





%What to represent
%	Components, calculators
%	resources
%		requirements
%		optimizable
%	resource distribution
%What inputs
%What outputs
%what actions




